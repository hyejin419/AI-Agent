{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM9aijYgSsW/OOsfGml7USz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **1. Reflection**\n","Reflection은 에이전트가 스스로 결과를 평가·비판 한 뒤 그 피드백을 상태(state)에 기록하고, 필요하면 수정 루프로 되돌아가 답을 개선하는 설계 패턴입니다. 보통 “작성 노드(답 생성) → 리플렉션 노드(자기평가) → 라우팅(조건부 엣지)”로 구성되며, 리플렉션 노드는 품질 기준(예: 정확성, 근거, 형식)을 점수·코멘트(score, critique)로 남깁니다. 라우터는 이 정보를 읽어 임계값 미달이면 작성 노드로 되감기, 충족하면 종료 노드로 이동합니다. 무한 루프를 막기 위해 max_iters 같은 반복 한도를 두며, 툴 호출과는 별개로 LLM의 자기검토 능력을 활용해 코드 생성, 질의응답, 체인드 리저닝 등의 정확도·일관성을 높이는 데 쓰입니다.\n","\n","<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2Fet5eoq%2FbtsQtfTBoz7%2FAAAAAAAAAAAAAAAAAAAAAM6C44vgBF-5pX8AStDskIMKM2c-gg9io9wsDgxh0NT0%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1759244399%26allow_ip%3D%26allow_referer%3D%26signature%3D9LqfZTAalr4qNMtDaaHHgd6RjCs%253D' width=600>\n"],"metadata":{"id":"O00tA-fruQV9"}},{"cell_type":"code","source":["import getpass\n","import os\n","\n","def _set_env(var: str):\n","    if not os.environ.get(var):\n","        os.environ[var] = getpass.getpass(f\"{var}: \")\n","\n","_set_env(\"OPENAI_API_KEY\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bYPtiUTDuZUo","executionInfo":{"status":"ok","timestamp":1757983018856,"user_tz":-540,"elapsed":4389,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}},"outputId":"26e8efd1-18f7-4b6e-8382-185d55c8cf5b"},"execution_count":1,"outputs":[{"name":"stdout","output_type":"stream","text":["OPENAI_API_KEY: ··········\n"]}]},{"cell_type":"code","source":["!pip install langchain_openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"_UuXogynvI-d","executionInfo":{"status":"ok","timestamp":1757983031385,"user_tz":-540,"elapsed":12535,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}},"outputId":"73b6874d-b16b-4137-e8b5-1ba12db97895"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain_openai\n","  Downloading langchain_openai-0.3.33-py3-none-any.whl.metadata (2.4 kB)\n","Collecting langchain-core<1.0.0,>=0.3.76 (from langchain_openai)\n","  Downloading langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n","Requirement already satisfied: openai<2.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (1.106.1)\n","Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.11.0)\n","Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (0.4.24)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (8.5.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (1.33)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (6.0.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (4.15.0)\n","Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (25.0)\n","Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (2.11.7)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (4.10.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (0.10.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (4.67.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.4)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.104.2->langchain_openai) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain_openai) (2025.8.3)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain_openai) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain_openai) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.76->langchain_openai) (3.0.0)\n","Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_openai) (3.11.3)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_openai) (1.0.0)\n","Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_openai) (0.24.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain_openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain_openai) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain_openai) (0.4.1)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.3)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.5.0)\n","Downloading langchain_openai-0.3.33-py3-none-any.whl (74 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_core-0.3.76-py3-none-any.whl (447 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: langchain-core, langchain_openai\n","  Attempting uninstall: langchain-core\n","    Found existing installation: langchain-core 0.3.75\n","    Uninstalling langchain-core-0.3.75:\n","      Successfully uninstalled langchain-core-0.3.75\n","Successfully installed langchain-core-0.3.76 langchain_openai-0.3.33\n"]}]},{"cell_type":"markdown","source":["### 1-1. 가사 생성"],"metadata":{"id":"yIUX3qOVvOIp"}},{"cell_type":"code","source":["from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","from langchain_openai import ChatOpenAI\n","\n","prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"당신은 5단락 노래가사를 훌륭하게 작성하는 작사 도우미입니다.\"\n","            \"사용자의 요청에 따라 최고의 가사를 작성하세요.\"\n","            \"사용자가 피드백을 제공할 경우, 이전 시도에서 개선된 수정본을 작성해 응답하세요.\",\n","        ),\n","        MessagesPlaceholder(variable_name=\"messages\"),\n","    ]\n",")\n","\n","llm = ChatOpenAI(model=\"gpt-5-nano\")\n","generate = prompt | llm"],"metadata":{"id":"ZGiRYqYUvX0G","executionInfo":{"status":"error","timestamp":1757983042515,"user_tz":-540,"elapsed":11122,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}},"colab":{"base_uri":"https://localhost:8080/","height":372},"outputId":"a159496e-f3e4-4222-f46f-3531dcd86b46"},"execution_count":3,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2861885691.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAIMessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseMessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHumanMessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatPromptTemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMessagesPlaceholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_openai\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatOpenAI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m prompt = ChatPromptTemplate.from_messages(\n","\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/prompts/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr_name)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mmodule_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dynamic_imports\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__spec__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m     \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/_import_utils.py\u001b[0m in \u001b[0;36mimport_attr\u001b[0;34m(attr_name, module_name, package)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\".{module_name}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpackage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"module '{package!r}.{module_name!r}' not found ({err})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/prompts/chat.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_msg_title_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt_values\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatPromptValue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageURL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBasePromptTemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdict\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDictPromptTemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImagePromptTemplate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/prompts/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mErrorCode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_message\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdumpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_parsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseOutputParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m from langchain_core.prompt_values import (\n\u001b[1;32m     30\u001b[0m     \u001b[0mChatPromptValueConcrete\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/output_parsers/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moverride\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLanguageModelOutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessages\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAnyMessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseMessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChatGeneration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGeneration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr_name)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mmodule_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dynamic_imports\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__spec__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/_import_utils.py\u001b[0m in \u001b[0;36mimport_attr\u001b[0;34m(attr_name, module_name, package)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\".{module_name}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpackage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"module '{package!r}.{module_name!r}' not found ({err})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/language_models/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGPT2TokenizerFast\u001b[0m  \u001b[0;31m# type: ignore[import-not-found]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0m_HAS_TRANSFORMERS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2300\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2301\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2302\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2303\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2304\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mModuleNotFoundError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   2328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2329\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2330\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2331\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2332\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"__file__\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_LazyModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefine_import_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m__spec__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36mdefine_import_structure\u001b[0;34m(module_path, prefix)\u001b[0m\n\u001b[1;32m   2849\u001b[0m     \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mwill\u001b[0m \u001b[0madd\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mprefix\u001b[0m \u001b[0mto\u001b[0m \u001b[0mall\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreturned\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2850\u001b[0m     \"\"\"\n\u001b[0;32m-> 2851\u001b[0;31m     \u001b[0mimport_structure\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_import_structure_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2852\u001b[0m     \u001b[0mspread_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspread_import_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimport_structure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36mcreate_import_structure_from_path\u001b[0;34m(module_path)\u001b[0m\n\u001b[1;32m   2562\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2563\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"__pycache__\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2564\u001b[0;31m             \u001b[0mimport_structure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_import_structure_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2566\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36mcreate_import_structure_from_path\u001b[0;34m(module_path)\u001b[0m\n\u001b[1;32m   2685\u001b[0m         \u001b[0;31m# These objects are exported with the file backends.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2686\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"__all__\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_content\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2687\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0m_all_object\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfetch__all__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2688\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m_all_object\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexported_objects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2689\u001b[0m                     \u001b[0mbackends\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_requirements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36mfetch__all__\u001b[0;34m(file_content)\u001b[0m\n\u001b[1;32m   2467\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_content\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2468\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2469\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__all__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2470\u001b[0m             \u001b[0mstart_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["lyric = \"\"\n","request = HumanMessage(\n","    content=\"이별에 대한 가사를 작성해주세요.\"\n",")\n","for chunk in generate.stream({\"messages\": [request]}):\n","    print(chunk.content, end=\"\")\n","    lyric += chunk.content"],"metadata":{"id":"7CN6e39pxLb5","executionInfo":{"status":"aborted","timestamp":1757983042527,"user_tz":-540,"elapsed":1,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1-2. 가사 개선"],"metadata":{"id":"UNrlErf7x2jC"}},{"cell_type":"code","source":["reflection_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"당신은 가사를 채점하는 작사가입니다. 사용자가 제출한 작사에 대한 비평과 개선 사항을 작성하세요.\"\n","            \"가사의 길이, 깊이, 문체 등을 포함해 구체적인 개선 요청을 제공하세요.\",\n","        ),\n","        MessagesPlaceholder(variable_name=\"messages\"),\n","    ]\n",")\n","reflect = reflection_prompt | llm"],"metadata":{"id":"Rdd-4vbDx7dG","executionInfo":{"status":"aborted","timestamp":1757983042551,"user_tz":-540,"elapsed":23,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reflection = \"\"\n","for chunk in reflect.stream({\"messages\": [request, HumanMessage(content=lyric)]}):\n","    print(chunk.content, end=\"\")\n","    reflection += chunk.content"],"metadata":{"id":"YclcLCRryQgV","executionInfo":{"status":"aborted","timestamp":1757983042560,"user_tz":-540,"elapsed":28245,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for chunk in generate.stream(\n","    {\"messages\": [request, AIMessage(content=lyric), HumanMessage(content=reflection)]}\n","):\n","    print(chunk.content, end=\"\")"],"metadata":{"id":"VMpF7eERyedQ","executionInfo":{"status":"aborted","timestamp":1757983042561,"user_tz":-540,"elapsed":28243,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1-3. Graph로 Reflection 구현\n","\n","<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FKZUhB%2FbtsQxetHmFz%2FAAAAAAAAAAAAAAAAAAAAAP0EuRkgL4J0CjrSQh0IKSN45ducYKse-WsdmcfUNwRn%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1759244399%26allow_ip%3D%26allow_referer%3D%26signature%3Da5V79BTw4md0u%252FyHl1YhcHNPRpU%253D'>"],"metadata":{"id":"OwY0wuF7y4Q_"}},{"cell_type":"code","source":["!pip install langgraph"],"metadata":{"collapsed":true,"id":"luOMCK5VzXjw","executionInfo":{"status":"aborted","timestamp":1757983042562,"user_tz":-540,"elapsed":28241,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from typing import Annotated\n","from typing_extensions import TypedDict\n","\n","from langgraph.graph import END, StateGraph, START\n","from langgraph.graph.message import add_messages\n","from langgraph.checkpoint.memory import MemorySaver\n","\n","\n","class State(TypedDict):\n","    messages: Annotated[list, add_messages]"],"metadata":{"id":"H52k5ZHfzcUx","executionInfo":{"status":"aborted","timestamp":1757983042563,"user_tz":-540,"elapsed":28240,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generation_node(state: State) -> State:\n","    return {\"messages\": [generate.invoke(state[\"messages\"])]}"],"metadata":{"id":"Oyyxb12dzmaL","executionInfo":{"status":"aborted","timestamp":1757983042564,"user_tz":-540,"elapsed":28241,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def reflection_node(state: State) -> State:\n","    cls_map = {\"ai\": AIMessage, \"human\": HumanMessage}\n","\n","    # 첫번째 사용자 요청 + 생성메시지 (reflection_node's input)\n","    # 첫번째 사용자 요청 + 생성메시지 + 피드백메시지 (generation_node's input)\n","    # 첫번째 사용자 요청 + 생성메시지 + 피드백메시지 + 수정된 생성메시지 (reflection_node's input)\n","    # 첫번째 사용자 요청 + 생성메시지 + 피드백메시지 + 수정된 생성메시지 + 피드백메시지 (generation_node's input)\n","    # ...\n","    translated = [state[\"messages\"][0]] + [\n","        cls_map[msg.type](content=msg.content) for msg in state[\"messages\"][1:]\n","    ]\n","    # translated = [state[\"messages\"][0]] + [\n","    #     cls_map[msg.type](content=msg.content) for msg in state[\"messages\"][-2:]\n","    # ]\n","    res = reflect.invoke(translated)\n","\n","    return {\"messages\": [HumanMessage(content=res.content)]}"],"metadata":{"id":"QtArj7nZzzSN","executionInfo":{"status":"aborted","timestamp":1757983042564,"user_tz":-540,"elapsed":28241,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["graph_builder = StateGraph(State)\n","graph_builder.add_node(\"generate\", generation_node)\n","graph_builder.add_node(\"reflect\", reflection_node)\n","graph_builder.add_edge(START, \"generate\")"],"metadata":{"id":"wD_QI7fz0Wv6","executionInfo":{"status":"aborted","timestamp":1757983042565,"user_tz":-540,"elapsed":28238,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from typing import Literal\n","from langgraph.graph import END\n","\n","def should_continue(state: State) -> Literal[\"reflect\", END]:\n","    if len(state[\"messages\"]) > 6:\n","        return END\n","    return \"reflect\"\n","\n","\n","graph_builder.add_conditional_edges(\"generate\", should_continue)"],"metadata":{"id":"EsNa05hh0nUc","executionInfo":{"status":"aborted","timestamp":1757983042566,"user_tz":-540,"elapsed":28235,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["graph_builder.add_edge(\"reflect\", \"generate\")"],"metadata":{"id":"45QkgXYs08sO","executionInfo":{"status":"aborted","timestamp":1757983042567,"user_tz":-540,"elapsed":28234,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["memory = MemorySaver()\n","graph = graph_builder.compile(checkpointer=memory)\n","graph"],"metadata":{"id":"plCi79re1CHL","executionInfo":{"status":"aborted","timestamp":1757983042568,"user_tz":-540,"elapsed":28232,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["config = {\"configurable\": {\"thread_id\": \"1\"}}"],"metadata":{"id":"GsrXCOVN1I_a","executionInfo":{"status":"aborted","timestamp":1757983042569,"user_tz":-540,"elapsed":28233,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for event in graph.stream(\n","    {\n","        \"messages\": [\n","            HumanMessage(\n","                content=\"이별에 대한 가사를 작성해주세요.\"\n","            )\n","        ],\n","    },\n","    config,\n","):\n","    print(event)\n","    print(\"---\")"],"metadata":{"id":"dx5OcAQz1Q_S","executionInfo":{"status":"aborted","timestamp":1757983042570,"user_tz":-540,"elapsed":28232,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["state = graph.get_state(config)\n","state"],"metadata":{"collapsed":true,"id":"NgEi_brq1aWn","executionInfo":{"status":"aborted","timestamp":1757983042615,"user_tz":-540,"elapsed":17,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ChatPromptTemplate.from_messages(state.values[\"messages\"]).pretty_print()"],"metadata":{"id":"A4d1j6S82Rpb","executionInfo":{"status":"aborted","timestamp":1757983042617,"user_tz":-540,"elapsed":6,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **2. Reflextion 구현**\n","[“Reflexion: Language Agents with Verbal Reinforcement Learning”](https://arxiv.org/abs/2303.11366)은, 2023년 3월 20일 최초 제출, 2023년 10월 10일 v4로 개정된 논문입니다. 저자는 Noah Shinn 외 5명이고, 핵심 내용은 언어 에이전트가 스스로 언어적 피드백(반성문)을 생성·메모리에 저장해 다음 시도에 반영함으로써 성능을 높이는 프레임워크를 제안했다는 점입니다. HumanEval 등에서 유의미한 향상을 보고합니다.\n","\n","<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2Fdzon1Q%2FbtsQxdO7zsM%2FAAAAAAAAAAAAAAAAAAAAAIv8GnJo2Z7lQar4RlJWoaap2PH03wadiph8ot4leqkE%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1759244399%26allow_ip%3D%26allow_referer%3D%26signature%3D8FwKXg927T0ByPpvHRMXDCmMW6w%253D'>\n","\n","* Actor (LM): 실제 행동(답안 작성, 코드 생성 등)을 내는 언어모델입니다.\n","* Evaluator (LM): Actor가 낸 결과를 내부적으로 평가합니다(정확성·형식·테스트 통과 여부 판단 등).\n","* Self-reflection (LM): 평가 결과를 바탕으로 “다음에는 이렇게 고치자” 같은 반성문(Reflective text)을 만들어 냅니다.\n","* Trajectory (short-term memory): 이번 시도에서의 행동/관찰 기록(a₀, o₀, …)을 담는 단기 메모리입니다.\n","* Experience (long-term memory): 누적된 반성문을 쌓아두는 장기 메모리(mem)입니다. 이후 시도에서 프롬프트에 이 기억을 넣어 같은 실수를 반복하지 않게 합니다.\n","* Environment: 외부에서 관찰/보상(예: 유닛 테스트의 통과/실패, 웹툴의 응답 등)을 제공합니다. 외부 피드백이 있으면 Evaluator의 판단과 함께 사용됩니다.\n","\n","<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2Fmii1M%2FbtsQzJFXs6L%2FAAAAAAAAAAAAAAAAAAAAABlDou97baB3Ry75PiiSdFP4Aml0fM58iNNa5PCw8tAm%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1759244399%26allow_ip%3D%26allow_referer%3D%26signature%3D4AJfc3vS%252BrrpVpN%252BWzMG7%252BP%252FfxE%253D'>"],"metadata":{"id":"CTMU7wjN2Wfr"}},{"cell_type":"code","source":["def _set_env(var: str):\n","    if not os.environ.get(var):\n","        os.environ[var] = getpass.getpass(f\"{var}: \")\n","\n","_set_env(\"TAVILY_API_KEY\")"],"metadata":{"id":"_uGBAHFe21hq","executionInfo":{"status":"aborted","timestamp":1757983042617,"user_tz":-540,"elapsed":5,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_openai import ChatOpenAI\n","\n","llm = ChatOpenAI(model=\"gpt-5-nano\")"],"metadata":{"id":"oXV1EDjC7xb9","executionInfo":{"status":"aborted","timestamp":1757983042618,"user_tz":-540,"elapsed":5,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install langchain_community"],"metadata":{"collapsed":true,"id":"0wLu2O4V7500","executionInfo":{"status":"aborted","timestamp":1757983042618,"user_tz":-540,"elapsed":4,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install langchain-tavily"],"metadata":{"collapsed":true,"id":"ipygY3zR79A8","executionInfo":{"status":"aborted","timestamp":1757983042619,"user_tz":-540,"elapsed":4,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_tavily import TavilySearch\n","\n","tavily_tool = TavilySearch(max_results=5)"],"metadata":{"id":"htBVlaLh8JNO","executionInfo":{"status":"aborted","timestamp":1757983042620,"user_tz":-540,"elapsed":28268,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2-1. 필요한 데이터 클래스 정의\n","Reflection - 놓친것 / 불필요한 것"],"metadata":{"id":"S65fmbex8Q2M"}},{"cell_type":"code","source":["from langchain_core.messages import HumanMessage, ToolMessage\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","from pydantic import BaseModel, Field\n","\n","class Reflection(BaseModel):\n","    missing: str = Field(description=\"누락되거나 부족한 부분에 대한 비평\")\n","    superfluous: str = Field(description=\"불필요한 부분에 대한 비평\")"],"metadata":{"id":"ez3zVu6Y8XRu","executionInfo":{"status":"aborted","timestamp":1757983042620,"user_tz":-540,"elapsed":28268,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# AnswerQuestion - 답변 / 답변에 대한 반성 / 개선하기 위한 검색 쿼리\n","class AnswerQuestion(BaseModel):\n","    answer: str = Field(description=\"질문에 대한 10문장 이내의 자세한 답변\")\n","    search_queries: list[str] = Field(\n","        description=\"현재 답변에 대한 비평을 해결하기 위한 추가 조사를 위한 1~3개의 웹 검색 쿼리\"\n","    )\n","    reflection: Reflection = Field(description=\"답변에 대한 자기반성 내용\")"],"metadata":{"id":"W2h6-91e8jmU","executionInfo":{"status":"aborted","timestamp":1757983042621,"user_tz":-540,"elapsed":28269,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Responder - 구조화된 출력을 위한 답변기\n","class Responder:\n","    def __init__(self, runnable):\n","        self.runnable = runnable # Chain\n","\n","    def respond(self, state: dict):\n","        response = self.runnable.invoke(\n","            {\"messages\": state[\"messages\"]}\n","        )\n","        return {\"messages\": response}"],"metadata":{"id":"lJlMqnOE83JG","executionInfo":{"status":"aborted","timestamp":1757983042621,"user_tz":-540,"elapsed":28269,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2-2. 초기 답변기 만들기 (Initial responder)\n","초기 답변을 위한 Chain 생성 -출력 스키마를 도구로 사용"],"metadata":{"id":"FU2FoHQb9IAo"}},{"cell_type":"code","source":["import datetime\n","\n","actor_prompt_template = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"\"\"당신은 전문 연구자입니다.\n","\n","            1. {first_instruction}\n","            2. <Reflect> 생성한 답변을 다시 되돌아보고 개선할 수 있도록 비판하세요.\n","            3. <Recommend search queries> 답변의 질을 높이기 위해 추가적으로 조사해야 할 정보에 대한 웹 검색 쿼리를 추천하세요.\"\"\",\n","        ),\n","        MessagesPlaceholder(variable_name=\"messages\"),\n","        (\n","            \"user\",\n","            \"\\n\\n<Reflect> 사용자 원래 질문과 지금까지의 행동을 되돌아보세요.\"\n","        ),\n","    ]\n",")\n","\n","initial_answer_chain = actor_prompt_template.partial(\n","    first_instruction=\"질문에 대한 10문장 이내의 자세한 답변을 제공해주세요.\", # 초기 답변\n",") | llm.bind_tools(tools=[AnswerQuestion], tool_choice=\"any\")"],"metadata":{"id":"Gaeci0zx9R24","executionInfo":{"status":"aborted","timestamp":1757983042622,"user_tz":-540,"elapsed":28269,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["* [구조화 출력을 위해 스키마를 도구로 사용하는 방법](https://python.langchain.com/docs/concepts/structured_outputs/#using-tool-calling)"],"metadata":{"id":"TZHy_mNj-Fye"}},{"cell_type":"code","source":["llm_with_tool = llm.bind_tools(tools=[AnswerQuestion], tool_choice=\"any\")\n","response = llm_with_tool.invoke([HumanMessage(content=\"AI Agent가 무엇인가요?\")])\n","print(response)"],"metadata":{"id":"b54xDdQi-A6h","executionInfo":{"status":"aborted","timestamp":1757983042623,"user_tz":-540,"elapsed":1,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response.tool_calls[0]['args']"],"metadata":{"id":"hzZhFQmV-gk-","executionInfo":{"status":"aborted","timestamp":1757983042659,"user_tz":-540,"elapsed":36,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["first_responder = Responder(runnable=initial_answer_chain)\n","first_responder"],"metadata":{"id":"DgTqZhGf-r5-","executionInfo":{"status":"aborted","timestamp":1757983042660,"user_tz":-540,"elapsed":23,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["example_question = \"AI Agent가 무엇인가요?\"\n","initial = first_responder.respond(\n","    {\"messages\": [HumanMessage(content=example_question)]}\n",")\n","\n","initial"],"metadata":{"id":"1yeK_ap6-8FN","executionInfo":{"status":"aborted","timestamp":1757983042660,"user_tz":-540,"elapsed":17,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# tool 호출 결과 확인 (AnswerQuestion 에 맞춰 출력 생성)\n","initial[\"messages\"].tool_calls[0][\"args\"]"],"metadata":{"id":"wcpyZjLM_INq","executionInfo":{"status":"aborted","timestamp":1757983042661,"user_tz":-540,"elapsed":18,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2-3. 수정 단계(Revision)"],"metadata":{"id":"ljJhPDzhB7X0"}},{"cell_type":"code","source":["class ReviseAnswer(AnswerQuestion):\n","    # 답변 > 반성 > 근거 인용 > 검색 제안\n","    \"\"\"Revise your original answer to your question. Provide an answer, reflection,\n","\n","    cite your reflection with references, and finally\n","    add search queries to improve the answer.\"\"\"\n","\n","    references: list[str] = Field(\n","        description=\"업데이트된 답변에 사용된 인용 출처\"\n","    )"],"metadata":{"id":"39H6b3vE_XJQ","executionInfo":{"status":"aborted","timestamp":1757983042662,"user_tz":-540,"elapsed":18,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["revise_instructions = \"\"\"이전 답변을 새로운 정보를 바탕으로 수정하세요.\n","- 이전 비평 내용을 활용해 중요한 정보를 추가해야 합니다.\n","  - 수정된 답변에는 반드시 숫자로 된 인용 표시를 포함하여 검증 가능하도록 해야 합니다.\n","  - 답변 하단에 \"참고문헌\" 섹션을 추가하세요 (이 부분은 단어 수 제한에 포함되지 않습니다). 형식은 다음과 같습니다:\n","    - [1] https://example.com\n","    - [2] https://example.com\n","\n","- 이전 비평 내용을 바탕으로 불필요한 정보를 제거하고, 최종 답변은 반드시 200자를 넘지 않도록 하세요.\n","\"\"\"\n","\n","revision_chain = actor_prompt_template.partial(\n","    first_instruction=revise_instructions,\n",") | llm.bind_tools(tools=[ReviseAnswer], tool_choice=\"any\")\n","\n","revisor = Responder(runnable=revision_chain)\n","revisor"],"metadata":{"id":"emh2NVvc_3ZI","executionInfo":{"status":"aborted","timestamp":1757983042663,"user_tz":-540,"elapsed":19,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 초기답변에서 생성한 웹검색 쿼리를 Tool 실행한 결과를 함께 입력\n","\n","import json\n","\n","revised = revisor.respond(\n","    {\n","        \"messages\": [\n","            HumanMessage(content=example_question),\n","            initial[\"messages\"],\n","            ToolMessage(\n","                tool_call_id=initial['messages'].additional_kwargs['tool_calls'][0]['id'],\n","                content=json.dumps(\n","                    tavily_tool.invoke(\n","                        {\n","                            \"query\": initial[\"messages\"].tool_calls[0][\"args\"]['search_queries'][0]\n","                        }\n","                    )\n","                ),\n","            ),\n","        ]\n","    }\n",")"],"metadata":{"id":"0or6GXFWAp9w","executionInfo":{"status":"aborted","timestamp":1757983042663,"user_tz":-540,"elapsed":19,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FnMKU1%2FbtsQwRziUZl%2FAAAAAAAAAAAAAAAAAAAAAASlhE2QFrMfwp2mVpfbJqW1PV9_JrnKxfrPSLouN6QH%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1759244399%26allow_ip%3D%26allow_referer%3D%26signature%3Dmo7gpz9i5fHpvBdpj4E4qkNltG4%253D'>"],"metadata":{"id":"ydxwBbpVBEiX"}},{"cell_type":"code","source":["revised[\"messages\"]"],"metadata":{"id":"34__RsTjBQPM","executionInfo":{"status":"aborted","timestamp":1757983042665,"user_tz":-540,"elapsed":20,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["revised[\"messages\"].tool_calls"],"metadata":{"id":"3Z3d0vBVBcWe","executionInfo":{"status":"aborted","timestamp":1757983042666,"user_tz":-540,"elapsed":21,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2.4. 웹검색을 위한 툴 노드 생성"],"metadata":{"id":"80XXAc6HBkdm"}},{"cell_type":"code","source":["tavily_tool.batch(\n","    [\n","        {\"query\": initial[\"messages\"].tool_calls[0][\"args\"]['search_queries'][0]}\n","    ]\n",")"],"metadata":{"id":"iOgGmExdCECn","executionInfo":{"status":"aborted","timestamp":1757983042667,"user_tz":-540,"elapsed":22,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_core.tools import StructuredTool\n","from langgraph.prebuilt import ToolNode\n","\n","def run_queries(search_queries: list[str], **kwargs):\n","    \"\"\"Run the generated queries.\"\"\"\n","    return tavily_tool.batch([{\"query\": query} for query in search_queries])\n","\n","\n","tool_node = ToolNode(\n","    [\n","        StructuredTool.from_function(run_queries, name=AnswerQuestion.__name__),\n","        StructuredTool.from_function(run_queries, name=ReviseAnswer.__name__),\n","    ]\n",")"],"metadata":{"id":"_-6U0hxICNvs","executionInfo":{"status":"aborted","timestamp":1757983042668,"user_tz":-540,"elapsed":11,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2-5. 그래프 생성하기"],"metadata":{"id":"csjonBIeCkvK"}},{"cell_type":"code","source":["from langgraph.graph import END, StateGraph, START\n","from langgraph.graph.message import add_messages\n","from typing import Annotated\n","from typing_extensions import TypedDict\n","\n","\n","class State(TypedDict):\n","    messages: Annotated[list, add_messages]"],"metadata":{"id":"yHDujtlwCtK4","executionInfo":{"status":"aborted","timestamp":1757983042669,"user_tz":-540,"elapsed":11,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["MAX_ITERATIONS = 5\n","graph_builder = StateGraph(State)\n","graph_builder.add_node(\"draft\", first_responder.respond)\n","\n","graph_builder.add_node(\"execute_tools\", tool_node) # 웹 검색 진행\n","graph_builder.add_node(\"revise\", revisor.respond)\n","\n","graph_builder.add_edge(\"draft\", \"execute_tools\")\n","graph_builder.add_edge(\"execute_tools\", \"revise\")"],"metadata":{"id":"akxE18t8CyXg","executionInfo":{"status":"aborted","timestamp":1757983042669,"user_tz":-540,"elapsed":11,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def _get_num_iterations(state: list):\n","    i = 0\n","    for m in state[::-1]:\n","        if m.type not in {\"tool\", \"ai\"}:\n","            break\n","        i += 1\n","    return i\n","\n","def event_loop(state: list):\n","    num_iterations = _get_num_iterations(state[\"messages\"])\n","    if num_iterations > MAX_ITERATIONS:\n","        return END\n","    return \"execute_tools\""],"metadata":{"id":"pOHxHKgGDAa-","executionInfo":{"status":"aborted","timestamp":1757983042670,"user_tz":-540,"elapsed":11,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["graph_builder.add_conditional_edges(\"revise\", event_loop, [\"execute_tools\", END])\n","graph_builder.add_edge(START, \"draft\")\n","graph = graph_builder.compile()\n","graph"],"metadata":{"id":"_ttP6ZrxDXMT","executionInfo":{"status":"aborted","timestamp":1757983042671,"user_tz":-540,"elapsed":0,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["events = graph.stream(\n","    {\"messages\": [HumanMessage(content=\"AI Agent가 무엇인가요?\")]},\n","    stream_mode=\"values\",\n",")\n","for i, step in enumerate(events):\n","    print(f\"Step {i}\")\n","    step[\"messages\"][-1].pretty_print()"],"metadata":{"id":"f6ayEcEvDfAr","executionInfo":{"status":"aborted","timestamp":1757983042689,"user_tz":-540,"elapsed":28313,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **3. Plan & Execute**"],"metadata":{"id":"k1jPORU3Dr_X"}},{"cell_type":"code","source":["import getpass\n","import os\n","\n","def _set_env(var: str):\n","    if not os.environ.get(var):\n","        os.environ[var] = getpass.getpass(f\"{var}: \")\n","\n","_set_env(\"OPENAI_API_KEY\")\n","_set_env(\"TAVILY_API_KEY\")"],"metadata":{"id":"lR98YOMmILzx","executionInfo":{"status":"aborted","timestamp":1757983042690,"user_tz":-540,"elapsed":28314,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install langchain_community"],"metadata":{"collapsed":true,"id":"p-kJvgU6IZkJ","executionInfo":{"status":"aborted","timestamp":1757983042691,"user_tz":-540,"elapsed":28313,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_community.tools.tavily_search import TavilySearchResults"],"metadata":{"id":"seC6BXqMIm0W","executionInfo":{"status":"aborted","timestamp":1757983042691,"user_tz":-540,"elapsed":28313,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["search_tool = TavilySearchResults(max_results=3)\n","tools = [search_tool]"],"metadata":{"id":"4r34pjtbIxHL","executionInfo":{"status":"aborted","timestamp":1757983042692,"user_tz":-540,"elapsed":28311,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install langchain_openai"],"metadata":{"collapsed":true,"id":"BYbkMFMrI8vI","executionInfo":{"status":"aborted","timestamp":1757983042693,"user_tz":-540,"elapsed":28310,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install langgraph"],"metadata":{"collapsed":true,"id":"rbLSg7B-JEHV","executionInfo":{"status":"aborted","timestamp":1757983042694,"user_tz":-540,"elapsed":28310,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ReAct 패턴\n","# 추론 -> 행동 -> 관찰 -> 답변,  자동으로 생성\n","from langchain_openai import ChatOpenAI\n","from langgraph.prebuilt import create_react_agent\n","\n","llm = ChatOpenAI(model=\"gpt-5-nano\")\n","prompt = \"You are a helpful assistant.\"\n","plan_executor = create_react_agent(llm, tools, prompt=prompt)\n","plan_executor"],"metadata":{"id":"-_Zne9sHJIal","executionInfo":{"status":"aborted","timestamp":1757983042694,"user_tz":-540,"elapsed":28308,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plan_executor.invoke({'messages': [('user', '2025년 한국의 최저시급은 얼마입니까?')]})"],"metadata":{"id":"d7AEyd1cJe5P","executionInfo":{"status":"aborted","timestamp":1757983042695,"user_tz":-540,"elapsed":28307,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pydantic import BaseModel, Field\n","from typing import List"],"metadata":{"id":"nn7GnViKKQ0P","executionInfo":{"status":"aborted","timestamp":1757983042695,"user_tz":-540,"elapsed":28307,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Plan(BaseModel):\n","    \"\"\"Plan to follow in future\"\"\"\n","\n","    steps: List[str] = Field(\n","        description=\"different steps to follow, should be in sorted order\"\n","    )"],"metadata":{"id":"T4ao8z9dKiCC","executionInfo":{"status":"aborted","timestamp":1757983042696,"user_tz":-540,"elapsed":28308,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","from langchain_core.messages import AIMessage, BaseMessage, HumanMessage"],"metadata":{"id":"1kqMeDqoKmcw","executionInfo":{"status":"aborted","timestamp":1757983042697,"user_tz":-540,"elapsed":28309,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["planner_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"\"\"For the given objective, come up with a simple step by step plan. \\\n","            This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n","            The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\"\"\",\n","        ),\n","        MessagesPlaceholder(variable_name=\"messages\"),\n","    ]\n",")\n","planner = planner_prompt | llm.with_structured_output(Plan)"],"metadata":{"id":"iY8RSLWOK3Lc","executionInfo":{"status":"aborted","timestamp":1757983042698,"user_tz":-540,"elapsed":28310,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plan_result = planner.invoke(\n","    {\n","        \"messages\": [HumanMessage(\n","            content=\"2025년 한국에서 개봉한 영화 중 가장 흥행한 영화는 무엇인가요?\",\n","        )]\n","    }\n",")\n","\n","plan_result"],"metadata":{"id":"Xc5iUhRvK8hC","executionInfo":{"status":"aborted","timestamp":1757983042699,"user_tz":-540,"elapsed":28309,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plan_result.steps"],"metadata":{"id":"eJccZTMNLFCk","executionInfo":{"status":"aborted","timestamp":1757983042700,"user_tz":-540,"elapsed":28308,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["replanner_prompt = ChatPromptTemplate.from_template(\n","    \"\"\"For the given objective, come up with a simple step by step plan. \\\n","    This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n","    The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n","\n","    Your objective was this:\n","    {input}\n","\n","    Your original plan was this:\n","    {plan}\n","\n","    You have currently done the follow steps:\n","    {past_steps}\n","\n","    Update your plan accordingly.\n","    If no more steps are needed and you can return to the user, then respond with that.\n","    Otherwise, fill out the plan. Only add steps to the plan that still NEED to be done.\n","    Do not return previously done steps as part of the plan.\"\"\"\n",")"],"metadata":{"id":"5P-ZGFhaL2u4","executionInfo":{"status":"aborted","timestamp":1757983042700,"user_tz":-540,"elapsed":28308,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from typing import Union\n","\n","class Response(BaseModel):\n","    \"\"\"Response to user.\"\"\"\n","\n","    response: str\n","\n","\n","class Act(BaseModel):\n","    \"\"\"Action to perform.\"\"\"\n","\n","    action: Union[Response, Plan] = Field(\n","        description=\"Action to perform. If you want to respond to user, use Response. \"\n","        \"If you need to further use tools to get the answer, use Plan.\"\n","    )"],"metadata":{"id":"6p6m2GtTMBPb","executionInfo":{"status":"aborted","timestamp":1757983042701,"user_tz":-540,"elapsed":28309,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["replanner = replanner_prompt | llm.with_structured_output(Act)"],"metadata":{"id":"zoQcuYoSMfVQ","executionInfo":{"status":"aborted","timestamp":1757983042702,"user_tz":-540,"elapsed":28310,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import operator\n","from typing import Annotated, List, Tuple\n","from typing_extensions import TypedDict\n","\n","class PlanExecute(TypedDict):\n","    input: str\n","    plan: List[str]\n","    past_steps: Annotated[List[Tuple], operator.add]\n","    response: str"],"metadata":{"id":"ti8hTGuRM9gu","executionInfo":{"status":"aborted","timestamp":1757983042711,"user_tz":-540,"elapsed":28319,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 계획 생성\n","def plan_step(state: PlanExecute):\n","    plan = planner.invoke({\"messages\": [(\"user\", state[\"input\"])]})\n","    return {\"plan\": plan.steps}"],"metadata":{"id":"xtMMRCcaNUI3","executionInfo":{"status":"aborted","timestamp":1757983042712,"user_tz":-540,"elapsed":28320,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 계획 실행\n","def execute_step(state: PlanExecute):\n","    plan = state[\"plan\"]\n","    plan_str = \"\\n\".join(f\"{i+1}. {step}\" for i, step in enumerate(plan))\n","\n","    task = plan[0]\n","    task_formatted = f\"\"\"For the following plan:\n","    {plan_str}\\n\\nYou are tasked with executing step {1}, {task}.\"\"\"\n","\n","    agent_response = plan_executor.invoke(\n","        {\"messages\": [(\"user\", task_formatted)]}\n","    )\n","    return {\n","        \"past_steps\": [(task, agent_response[\"messages\"][-1].content)], # 실행 완료한 계획과 결과 저장\n","    }"],"metadata":{"id":"OmqHBeDNNY3-","executionInfo":{"status":"aborted","timestamp":1757983042712,"user_tz":-540,"elapsed":28319,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 계획 수정\n","def replan_step(state: PlanExecute):\n","    output = replanner.invoke(state)\n","    if isinstance(output.action, Response): # 답변이 바로 가능한 상태\n","        return {\"response\": output.action.response}\n","    else:\n","        return {\"plan\": output.action.steps}"],"metadata":{"id":"mJV5gdv7NloT","executionInfo":{"status":"aborted","timestamp":1757983042713,"user_tz":-540,"elapsed":28320,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langgraph.graph import END\n","\n","def should_end(state: PlanExecute):\n","    if \"response\" in state and state[\"response\"]:\n","        return END\n","    else:\n","        return \"agent\""],"metadata":{"id":"q-qy5871OVgd","executionInfo":{"status":"aborted","timestamp":1757983042714,"user_tz":-540,"elapsed":28321,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langgraph.graph import StateGraph, START\n","\n","graph_builder = StateGraph(PlanExecute)\n","\n","\n","graph_builder.add_node(\"planner\", plan_step)\n","graph_builder.add_node(\"agent\", execute_step)\n","graph_builder.add_node(\"replan\", replan_step)\n","\n","graph_builder.add_edge(START, \"planner\")\n","\n","graph_builder.add_edge(\"planner\", \"agent\")\n","graph_builder.add_edge(\"agent\", \"replan\")\n","\n","graph_builder.add_conditional_edges(\n","    \"replan\",\n","    should_end,\n","    [\"agent\", END],\n",")\n","\n","graph = graph_builder.compile()"],"metadata":{"id":"NiC3qcZqOiEB","executionInfo":{"status":"aborted","timestamp":1757983042715,"user_tz":-540,"elapsed":28322,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["graph"],"metadata":{"id":"dUNsAmxbOzbO","executionInfo":{"status":"aborted","timestamp":1757983042716,"user_tz":-540,"elapsed":28321,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["config = {'recursion_limit': 50}\n","inputs = {'input': '2024년 노벨문학상 수상자의 출신국가는 어디인가요?'}\n","for event in graph.stream(inputs, config=config, stream_mode='values'):\n","    for k, v in event.items():\n","        print(k, v)\n","    print('*' * 50)"],"metadata":{"id":"pDcizFLCPBM-","executionInfo":{"status":"aborted","timestamp":1757983042716,"user_tz":-540,"elapsed":28319,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **4. 코드 수정을 반복하는 데이터 전처리 Agent**"],"metadata":{"id":"11FUGOAzPnhe"}},{"cell_type":"markdown","source":["### 클로드\n","클로드(Claude)는 앤트로픽(Anthropic)에서 개발한 대규모 언어 모델(LLM) 기반의 인공지능 챗봇으로, 사람과의 대화, 글쓰기, 요약, 코드 작성 등 다양한 작업을 수행할 수 있는 생성형 AI입니다. 이름은 인공지능의 선구자 클로드 섀넌(Claude Shannon)에서 따왔으며, “헌宪법 기반 AI(constitutional AI)” 접근법을 적용해 안전성과 투명성을 강화한 것이 특징입니다. 즉, 인간의 직접적인 지시보다는 미리 정해둔 원칙과 가이드라인을 통해 스스로 출력을 조율하도록 설계되었기 때문에, 사용자가 안심하고 활용할 수 있는 대화형 AI라는 점에서 주목받고 있습니다."],"metadata":{"id":"92vBShUf32Hw"}},{"cell_type":"code","source":["import getpass\n","import os\n","\n","def _set_env(var: str):\n","    if not os.environ.get(var):\n","        os.environ[var] = getpass.getpass(f\"{var}: \")\n","\n","_set_env(\"OPENAI_API_KEY\")\n","_set_env(\"ANTHROPIC_API_KEY\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fcBNNuAi4pf6","executionInfo":{"status":"ok","timestamp":1757986679080,"user_tz":-540,"elapsed":14970,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}},"outputId":"6664087a-35e5-4179-9780-c557d15d23e9"},"execution_count":1,"outputs":[{"name":"stdout","output_type":"stream","text":["OPENAI_API_KEY: ··········\n","ANTHROPIC_API_KEY: ··········\n"]}]},{"cell_type":"code","source":["from langchain_core.tools import tool\n","import pandas as pd"],"metadata":{"id":"0ZMtM90u5_d4","executionInfo":{"status":"ok","timestamp":1757986684199,"user_tz":-540,"elapsed":2044,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["@tool\n","def describe_data(csv: str) -> str:\n","    \"\"\"Describe the date column in the dataframe.\n","\n","    Args:\n","        csv: csv data path string\n","    \"\"\"\n","    df = pd.read_csv(csv)\n","    describe_str = f\"\"\"Data: {csv}\"\"\" + df.describe(include='all').to_string()\n","    return describe_str"],"metadata":{"id":"4QEYBj257Cqk","executionInfo":{"status":"ok","timestamp":1757986684202,"user_tz":-540,"elapsed":1,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["tools = [describe_data]"],"metadata":{"id":"16IAAEUX7IH8","executionInfo":{"status":"ok","timestamp":1757986684216,"user_tz":-540,"elapsed":13,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["!pip install langchain_openai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":922},"collapsed":true,"id":"eJ_wQJFm7ggD","executionInfo":{"status":"ok","timestamp":1757986702602,"user_tz":-540,"elapsed":18259,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}},"outputId":"250bb9c6-478d-4943-901c-100f68a88b59"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain_openai\n","  Downloading langchain_openai-0.3.33-py3-none-any.whl.metadata (2.4 kB)\n","Collecting langchain-core<1.0.0,>=0.3.76 (from langchain_openai)\n","  Downloading langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n","Requirement already satisfied: openai<2.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (1.106.1)\n","Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.11.0)\n","Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (0.4.24)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (8.5.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (1.33)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (6.0.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (4.15.0)\n","Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (25.0)\n","Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_openai) (2.11.7)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (4.10.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (0.10.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<2.0.0,>=1.104.2->langchain_openai) (4.67.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.4)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.104.2->langchain_openai) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain_openai) (2025.8.3)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain_openai) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.104.2->langchain_openai) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.76->langchain_openai) (3.0.0)\n","Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_openai) (3.11.3)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_openai) (1.0.0)\n","Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_openai) (0.24.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain_openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain_openai) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.76->langchain_openai) (0.4.1)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.4.3)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.5.0)\n","Downloading langchain_openai-0.3.33-py3-none-any.whl (74 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_core-0.3.76-py3-none-any.whl (447 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: langchain-core, langchain_openai\n","  Attempting uninstall: langchain-core\n","    Found existing installation: langchain-core 0.3.75\n","    Uninstalling langchain-core-0.3.75:\n","      Successfully uninstalled langchain-core-0.3.75\n","Successfully installed langchain-core-0.3.76 langchain_openai-0.3.33\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["langchain_core"]},"id":"c8e4adb138a741ab9a0fbcafd91bd584"}},"metadata":{}}]},{"cell_type":"code","source":["!pip install langchain_anthropic"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"XdHYy-BV7kwk","executionInfo":{"status":"ok","timestamp":1757986724525,"user_tz":-540,"elapsed":21865,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}},"outputId":"92fad46c-58e0-4412-af2e-212dc7ec33f0"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain_anthropic\n","  Downloading langchain_anthropic-0.3.20-py3-none-any.whl.metadata (1.9 kB)\n","Collecting anthropic<1,>=0.67.0 (from langchain_anthropic)\n","  Downloading anthropic-0.67.0-py3-none-any.whl.metadata (27 kB)\n","Requirement already satisfied: langchain-core<1.0.0,>=0.3.76 in /usr/local/lib/python3.12/dist-packages (from langchain_anthropic) (0.3.76)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain_anthropic) (2.11.7)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1,>=0.67.0->langchain_anthropic) (4.10.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1,>=0.67.0->langchain_anthropic) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1,>=0.67.0->langchain_anthropic) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic<1,>=0.67.0->langchain_anthropic) (0.10.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from anthropic<1,>=0.67.0->langchain_anthropic) (1.3.1)\n","Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from anthropic<1,>=0.67.0->langchain_anthropic) (4.15.0)\n","Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_anthropic) (0.4.24)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_anthropic) (8.5.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_anthropic) (1.33)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_anthropic) (6.0.2)\n","Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.76->langchain_anthropic) (25.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain_anthropic) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain_anthropic) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain_anthropic) (0.4.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->anthropic<1,>=0.67.0->langchain_anthropic) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic<1,>=0.67.0->langchain_anthropic) (2025.8.3)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic<1,>=0.67.0->langchain_anthropic) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic<1,>=0.67.0->langchain_anthropic) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.76->langchain_anthropic) (3.0.0)\n","Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_anthropic) (3.11.3)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_anthropic) (1.0.0)\n","Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_anthropic) (2.32.4)\n","Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_anthropic) (0.24.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_anthropic) (3.4.3)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.76->langchain_anthropic) (2.5.0)\n","Downloading langchain_anthropic-0.3.20-py3-none-any.whl (31 kB)\n","Downloading anthropic-0.67.0-py3-none-any.whl (317 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: anthropic, langchain_anthropic\n","Successfully installed anthropic-0.67.0 langchain_anthropic-0.3.20\n"]}]},{"cell_type":"code","source":["from langchain_openai import ChatOpenAI\n","from langchain_anthropic import ChatAnthropic\n","\n","llm_gpt = ChatOpenAI(model=\"gpt-5-nano\")\n","llm_with_tools = llm_gpt.bind_tools(tools, tool_choice=\"any\")"],"metadata":{"id":"Z62EQ5ch7t6R","executionInfo":{"status":"ok","timestamp":1757986746182,"user_tz":-540,"elapsed":21638,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["response = llm_with_tools.invoke(\n","    \"https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/diabetes.csv 이 데이터의 전처리를 해주세요.\"\n",")"],"metadata":{"id":"TUtN3ZzY77XB","executionInfo":{"status":"ok","timestamp":1757986752604,"user_tz":-540,"elapsed":6420,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["response.tool_calls[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IFdknTcC8smB","executionInfo":{"status":"ok","timestamp":1757986752646,"user_tz":-540,"elapsed":30,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}},"outputId":"b1039ac9-0b03-4769-e5bf-bd69278cd375"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'name': 'describe_data',\n"," 'args': {'csv': 'https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/diabetes.csv'},\n"," 'id': 'call_VLcYSy8dVc9G9Wwyt4rsOPfC',\n"," 'type': 'tool_call'}"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["response.tool_calls[0]['args']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Epn0A1H_9ssd","executionInfo":{"status":"ok","timestamp":1757986752690,"user_tz":-540,"elapsed":43,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}},"outputId":"b9c6f0b4-ae71-40cc-da5e-3db0f1ccbd8e"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'csv': 'https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/diabetes.csv'}"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["from pydantic import BaseModel, Field\n","\n","class code(BaseModel):\n","    \"\"\"Schema for code solutions.\"\"\"\n","\n","    prefix: str = Field(description=\"Description of the problem and approach\")\n","    imports: str = Field(description=\"Code block import statements\")\n","    code: str = Field(description=\"Code block not including import statements\")"],"metadata":{"id":"AcgM4Xgr9uN2","executionInfo":{"status":"ok","timestamp":1757986752721,"user_tz":-540,"elapsed":28,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["from langchain_core.prompts import ChatPromptTemplate\n","\n","GENERATE_CODE_TEMPLATE = \"\"\"\n","Given the following pandas `describe()` output of a dataset,\n","\n","write a **directly executable Python code** to:\n","1. handle missing values,\n","2. convert categorical columns,\n","3. ...any additional preprocessing needed,\n","4. prepare the dataset for machine learning.\n","\n","Here is the describe result of the dataset:\n","\\n ------- \\n  {context} \\n ------- \\n\n","\n","Do not wrap the code in a function and the response in any backticks or anything else. The code should be written as a flat script, so that it can be run immediately and any errors will be visible during execution.\n","Ensure any code you provide can be executed \\n\n","with all required imports and variables defined. Structure your answer with a description of the code solution. \\n\n","Then list the imports. And finally list the functioning code block.\n","\"\"\"\n","\n","code_gen_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"user\", GENERATE_CODE_TEMPLATE),\n","    ]\n",")"],"metadata":{"id":"MJ735Cj_-P8H","executionInfo":{"status":"ok","timestamp":1757986753027,"user_tz":-540,"elapsed":302,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["from langchain_anthropic import ChatAnthropic\n","\n","llm_claude= ChatAnthropic(model=\"claude-sonnet-4-20250514\")"],"metadata":{"id":"uDKkLBQ6-d3V","executionInfo":{"status":"ok","timestamp":1757986753028,"user_tz":-540,"elapsed":22,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["response.tool_calls[0]['args']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6yFi0R5h_18Q","executionInfo":{"status":"ok","timestamp":1757986753029,"user_tz":-540,"elapsed":7,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}},"outputId":"018ccfd2-2a3b-4d62-a2c9-91fa20d4029e"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'csv': 'https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/diabetes.csv'}"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["tool_result = describe_data.invoke(response.tool_calls[0]['args'])\n","print(tool_result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lKgUquw4_6JY","executionInfo":{"status":"ok","timestamp":1757986753250,"user_tz":-540,"elapsed":221,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}},"outputId":"4e1e873a-3b60-484a-ccb6-baf0285e06de"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Data: https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/diabetes.csv       Number of times pregnant  Plasma glucose concentration a 2 hours in an oral glucose tolerance test  Diastolic blood pressure (mm Hg)  Triceps skin fold thickness (mm)  2-Hour serum insulin (mu U/ml)  Body mass index (weight in kg/(height in m)^2)  Diabetes pedigree function  Age (years)  Class variable\n","count                768.000000                                                                768.000000                        768.000000                        768.000000                      768.000000                                      768.000000                  768.000000   768.000000      768.000000\n","mean                   3.845052                                                                120.894531                         69.105469                         20.536458                       79.799479                                       31.992578                    0.471876    33.240885        0.348958\n","std                    3.369578                                                                 31.972618                         19.355807                         15.952218                      115.244002                                        7.884160                    0.331329    11.760232        0.476951\n","min                    0.000000                                                                  0.000000                          0.000000                          0.000000                        0.000000                                        0.000000                    0.078000    21.000000        0.000000\n","25%                    1.000000                                                                 99.000000                         62.000000                          0.000000                        0.000000                                       27.300000                    0.243750    24.000000        0.000000\n","50%                    3.000000                                                                117.000000                         72.000000                         23.000000                       30.500000                                       32.000000                    0.372500    29.000000        0.000000\n","75%                    6.000000                                                                140.250000                         80.000000                         32.000000                      127.250000                                       36.600000                    0.626250    41.000000        1.000000\n","max                   17.000000                                                                199.000000                        122.000000                         99.000000                      846.000000                                       67.100000                    2.420000    81.000000        1.000000\n"]}]},{"cell_type":"code","source":["generated_code = llm_claude.invoke(\n","    code_gen_prompt.format_messages(context=tool_result)\n",")\n","print(\"generated_code\", generated_code)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S9KqzZH7_e1Y","executionInfo":{"status":"ok","timestamp":1757986770783,"user_tz":-540,"elapsed":17519,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}},"outputId":"432d27c4-fb66-46fb-ec2c-c3033f5e4783"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["generated_code content='## Description\\n\\nThis code will preprocess the diabetes dataset for machine learning by:\\n1. Loading the data from the provided URL\\n2. Handling missing values that are encoded as zeros (common in medical datasets)\\n3. Applying appropriate imputation strategies for different types of features\\n4. Scaling numerical features for better model performance\\n5. Splitting the data into training and testing sets\\n\\nThe dataset appears to have missing values encoded as zeros for several medical measurements (glucose, blood pressure, skin fold thickness, insulin, BMI), which need to be properly handled as true missing values and imputed.\\n\\n## Imports\\n\\n```python\\nimport pandas as pd\\nimport numpy as np\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.impute import SimpleImputer\\n```\\n\\n## Code\\n\\n```python\\nimport pandas as pd\\nimport numpy as np\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.impute import SimpleImputer\\n\\n# Load the dataset\\nurl = \"https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/diabetes.csv\"\\ndf = pd.read_csv(url)\\n\\nprint(\"Original dataset shape:\", df.shape)\\nprint(\"\\\\nFirst few rows:\")\\nprint(df.head())\\n\\n# Display column names for reference\\nprint(\"\\\\nColumn names:\")\\nfor i, col in enumerate(df.columns):\\n    print(f\"{i}: {col}\")\\n\\n# Handle missing values encoded as zeros\\n# These columns should not have zero values in medical context\\ncolumns_with_zero_as_missing = [\\n    \\'Plasma glucose concentration a 2 hours in an oral glucose tolerance test\\',\\n    \\'Diastolic blood pressure (mm Hg)\\',\\n    \\'Triceps skin fold thickness (mm)\\',\\n    \\'2-Hour serum insulin (mu U/ml)\\',\\n    \\'Body mass index (weight in kg/(height in m)^2)\\'\\n]\\n\\n# Replace zeros with NaN for these columns\\nfor col in columns_with_zero_as_missing:\\n    df[col] = df[col].replace(0, np.nan)\\n\\nprint(\"\\\\nMissing values after converting zeros to NaN:\")\\nprint(df.isnull().sum())\\n\\n# Separate features and target\\nX = df.drop(\\'Class variable\\', axis=1)\\ny = df[\\'Class variable\\']\\n\\n# Handle missing values with median imputation (robust to outliers)\\nimputer = SimpleImputer(strategy=\\'median\\')\\nX_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\\n\\nprint(\"\\\\nMissing values after imputation:\")\\nprint(X_imputed.isnull().sum())\\n\\n# Check for any remaining missing values\\nif X_imputed.isnull().sum().sum() > 0:\\n    print(\"Warning: Still have missing values after imputation\")\\nelse:\\n    print(\"All missing values handled successfully\")\\n\\n# Split the data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X_imputed, y, test_size=0.2, random_state=42, stratify=y\\n)\\n\\nprint(f\"\\\\nTraining set shape: {X_train.shape}\")\\nprint(f\"Testing set shape: {X_test.shape}\")\\nprint(f\"Training set class distribution:\\\\n{y_train.value_counts()}\")\\n\\n# Scale the features\\nscaler = StandardScaler()\\nX_train_scaled = scaler.fit_transform(X_train)\\nX_test_scaled = scaler.transform(X_test)\\n\\n# Convert back to DataFrames for easier handling\\nX_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\\nX_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\\n\\nprint(\"\\\\nFeature scaling completed\")\\nprint(\"Training set statistics after scaling:\")\\nprint(X_train_scaled.describe().round(3))\\n\\nprint(\"\\\\nDataset is now ready for machine learning!\")\\nprint(f\"Final training features shape: {X_train_scaled.shape}\")\\nprint(f\"Final testing features shape: {X_test_scaled.shape}\")\\nprint(f\"Target variable shape - train: {y_train.shape}, test: {y' additional_kwargs={} response_metadata={'id': 'msg_014J5VsjRBEX3Ukc6W7SuL7s', 'model': 'claude-sonnet-4-20250514', 'stop_reason': 'max_tokens', 'stop_sequence': None, 'usage': {'cache_creation': {'ephemeral_1h_input_tokens': 0, 'ephemeral_5m_input_tokens': 0}, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 756, 'output_tokens': 1024, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-sonnet-4-20250514'} id='run--7c9badc9-71cd-4140-8c65-3990e19f815f-0' usage_metadata={'input_tokens': 756, 'output_tokens': 1024, 'total_tokens': 1780, 'input_token_details': {'cache_read': 0, 'cache_creation': 0, 'ephemeral_5m_input_tokens': 0, 'ephemeral_1h_input_tokens': 0}}\n"]}]},{"cell_type":"code","source":["code_structurer = llm_gpt.with_structured_output(code)\n","code_solution = code_structurer.invoke(generated_code.content)\n","print(\"code_solution\", code_solution)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ouOHI6lYAaL0","executionInfo":{"status":"ok","timestamp":1757986788371,"user_tz":-540,"elapsed":17590,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}},"outputId":"8e9bb6a3-6904-40d5-9365-ba33d895eb16"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["code_solution prefix=\"Preprocess the diabetes dataset by loading it from the provided URL, treating medically implausible zeros as missing values, imputing missing values, scaling numerical features, and splitting into train/test sets. The dataset may use different target column names (e.g., 'Outcome' or 'Class variable'), so the code detects the target column robustly. Only the medically invalid zeros in Glucose, BloodPressure, SkinThickness, Insulin, and BMI are replaced with NaN before imputation.\" imports='import pandas as pd\\nimport numpy as np\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import StandardScaler\\nfrom sklearn.impute import SimpleImputer' code='# Load the dataset\\nurl = \"https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/diabetes.csv\"\\ndf = pd.read_csv(url)\\n\\n# Detect target column robustly\\nif \\'Outcome\\' in df.columns:\\n    target_col = \\'Outcome\\'\\nelif \\'Class variable\\' in df.columns:\\n    target_col = \\'Class variable\\'\\nelse:\\n    raise ValueError(\"Target column not found. Expected \\'Outcome\\' or \\'Class variable\\'.\")\\n\\ny = df[target_col]\\nX = df.drop(columns=[target_col])\\n\\n# Identify columns where zeros are considered missing (medical context)\\nzero_as_missing_cols = [\\'Glucose\\',\\'BloodPressure\\',\\'SkinThickness\\',\\'Insulin\\',\\'BMI\\']\\n\\n# Replace zeros with NaN for these columns when present\\nfor col in zero_as_missing_cols:\\n    if col in X.columns:\\n        X[col] = X[col].replace(0, np.nan)\\n\\nprint(\"Missing values per column before imputation:\")\\nprint(X.isnull().sum().sort_values(ascending=False))\\n\\n# Impute missing values (median is robust to outliers) for numeric features\\nimputer = SimpleImputer(strategy=\\'median\\')\\nX_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\\n\\nprint(\"\\\\nMissing values after imputation:\")\\nprint(X_imputed.isnull().sum())\\n\\n# Verify there are no remaining missing values\\nif X_imputed.isnull().sum().sum() > 0:\\n    print(\"Warning: Still have missing values after imputation\")\\nelse:\\n    print(\"All missing values handled successfully\")\\n\\n# Split the data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X_imputed, y, test_size=0.2, random_state=42, stratify=y\\n)\\n\\nprint(f\"\\\\nTraining set shape: {X_train.shape}\")\\nprint(f\"Testing set shape: {X_test.shape}\")\\nprint(f\"Training set class distribution:\\\\n{y_train.value_counts()}\")\\n\\n# Scale numerical features\\nscaler = StandardScaler()\\nX_train_scaled = scaler.fit_transform(X_train)\\nX_test_scaled = scaler.transform(X_test)\\n\\n# Convert back to DataFrames for easier handling\\nX_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\\nX_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\\n\\nprint(\"\\\\nFeature scaling completed\")\\nprint(\"Training set statistics after scaling:\")\\nprint(X_train_scaled.describe().round(3))\\n\\nprint(\"\\\\nDataset is now ready for machine learning!\")\\nprint(f\"Final training features shape: {X_train_scaled.shape}\")\\nprint(f\"Final testing features shape: {X_test_scaled.shape}\")\\nprint(f\"Target variable shape - train: {y_train.shape}, test: {y_test.shape}\")\\n'\n"]}]},{"cell_type":"code","source":["print(code_solution.imports)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xgbGWndhBE6T","executionInfo":{"status":"ok","timestamp":1757986788380,"user_tz":-540,"elapsed":8,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}},"outputId":"6cc2e6f2-0477-422c-8905-cb6f144a9d0e"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.impute import SimpleImputer\n"]}]},{"cell_type":"code","source":["print(code_solution.code)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8jnLeg_fBSWo","executionInfo":{"status":"ok","timestamp":1757986788406,"user_tz":-540,"elapsed":25,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}},"outputId":"76211545-d8c7-4d59-d170-34c61dc612b8"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["# Load the dataset\n","url = \"https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/diabetes.csv\"\n","df = pd.read_csv(url)\n","\n","# Detect target column robustly\n","if 'Outcome' in df.columns:\n","    target_col = 'Outcome'\n","elif 'Class variable' in df.columns:\n","    target_col = 'Class variable'\n","else:\n","    raise ValueError(\"Target column not found. Expected 'Outcome' or 'Class variable'.\")\n","\n","y = df[target_col]\n","X = df.drop(columns=[target_col])\n","\n","# Identify columns where zeros are considered missing (medical context)\n","zero_as_missing_cols = ['Glucose','BloodPressure','SkinThickness','Insulin','BMI']\n","\n","# Replace zeros with NaN for these columns when present\n","for col in zero_as_missing_cols:\n","    if col in X.columns:\n","        X[col] = X[col].replace(0, np.nan)\n","\n","print(\"Missing values per column before imputation:\")\n","print(X.isnull().sum().sort_values(ascending=False))\n","\n","# Impute missing values (median is robust to outliers) for numeric features\n","imputer = SimpleImputer(strategy='median')\n","X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n","\n","print(\"\\nMissing values after imputation:\")\n","print(X_imputed.isnull().sum())\n","\n","# Verify there are no remaining missing values\n","if X_imputed.isnull().sum().sum() > 0:\n","    print(\"Warning: Still have missing values after imputation\")\n","else:\n","    print(\"All missing values handled successfully\")\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_imputed, y, test_size=0.2, random_state=42, stratify=y\n",")\n","\n","print(f\"\\nTraining set shape: {X_train.shape}\")\n","print(f\"Testing set shape: {X_test.shape}\")\n","print(f\"Training set class distribution:\\n{y_train.value_counts()}\")\n","\n","# Scale numerical features\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Convert back to DataFrames for easier handling\n","X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\n","X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\n","\n","print(\"\\nFeature scaling completed\")\n","print(\"Training set statistics after scaling:\")\n","print(X_train_scaled.describe().round(3))\n","\n","print(\"\\nDataset is now ready for machine learning!\")\n","print(f\"Final training features shape: {X_train_scaled.shape}\")\n","print(f\"Final testing features shape: {X_test_scaled.shape}\")\n","print(f\"Target variable shape - train: {y_train.shape}, test: {y_test.shape}\")\n","\n"]}]},{"cell_type":"code","source":["!pip install langgraph"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"4DVvzMPiBXRi","executionInfo":{"status":"ok","timestamp":1757986797826,"user_tz":-540,"elapsed":9419,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}},"outputId":"05419785-3072-4b1a-c24b-7f66eccdc6d5"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langgraph\n","  Downloading langgraph-0.6.7-py3-none-any.whl.metadata (6.8 kB)\n","Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.76)\n","Collecting langgraph-checkpoint<3.0.0,>=2.1.0 (from langgraph)\n","  Downloading langgraph_checkpoint-2.1.1-py3-none-any.whl.metadata (4.2 kB)\n","Collecting langgraph-prebuilt<0.7.0,>=0.6.0 (from langgraph)\n","  Downloading langgraph_prebuilt-0.6.4-py3-none-any.whl.metadata (4.5 kB)\n","Collecting langgraph-sdk<0.3.0,>=0.2.2 (from langgraph)\n","  Downloading langgraph_sdk-0.2.6-py3-none-any.whl.metadata (1.5 kB)\n","Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.11.7)\n","Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.5.0)\n","Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.4.24)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (8.5.0)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n","Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n","Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n","Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n","Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph)\n","  Downloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n","Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.3)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.10.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.8.3)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.10)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n","Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n","Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.3.45->langchain-core>=0.1->langgraph) (0.24.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (3.4.3)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.3.1)\n","Downloading langgraph-0.6.7-py3-none-any.whl (153 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langgraph_checkpoint-2.1.1-py3-none-any.whl (43 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langgraph_prebuilt-0.6.4-py3-none-any.whl (28 kB)\n","Downloading langgraph_sdk-0.2.6-py3-none-any.whl (54 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ormsgpack-1.10.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n","Successfully installed langgraph-0.6.7 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.6 ormsgpack-1.10.0\n"]}]},{"cell_type":"code","source":["from langgraph.graph import StateGraph, MessagesState\n","\n","class State(MessagesState): # messages\n","    \"\"\"\n","    Represents the state of our graph.\n","\n","    Attributes:\n","        error : Binary flag for control flow to indicate whether test error was tripped\n","        context: Data summary\n","        generation : Code solution\n","        iterations : Number of tries\n","    \"\"\"\n","    error: str # yes or no\n","    context: str\n","    generation: str\n","    iterations: int\n","\n","graph_builder = StateGraph(State)"],"metadata":{"id":"BknrYKf5ExVb","executionInfo":{"status":"ok","timestamp":1757986797899,"user_tz":-540,"elapsed":59,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["from langchain_core.tools import tool\n","import pandas as pd\n","\n","@tool\n","def describe_data(csv: str) -> str:\n","    \"\"\"Describe the date column in the dataframe.\n","\n","    Args:\n","        csv: csv data path string\n","    \"\"\"\n","    df = pd.read_csv(csv)\n","    describe_str = f\"\"\"Data: {csv}\"\"\" + df.describe(include='all').to_string()\n","    return describe_str"],"metadata":{"id":"UEONK1waE7zo","executionInfo":{"status":"ok","timestamp":1757986797920,"user_tz":-540,"elapsed":16,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["llm_with_tools = llm_gpt.bind_tools(tools=[describe_data], tool_choice=\"any\")"],"metadata":{"id":"cK-51eKfFR7u","executionInfo":{"status":"ok","timestamp":1757986797967,"user_tz":-540,"elapsed":46,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["def chatbot(state: State):\n","    print(\"##### HI ! #####\")\n","    response = llm_with_tools.invoke(state[\"messages\"])\n","    print(\"첫번째 LLM 호출 결과 : \", response)\n","    return {\"messages\": [response]}\n","\n","graph_builder.add_node(\"chatbot\", chatbot)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xgN-vKitFn4i","executionInfo":{"status":"ok","timestamp":1757986797979,"user_tz":-540,"elapsed":9,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}},"outputId":"d6a3bf7b-655a-4f3e-98fe-abf2cf437932"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<langgraph.graph.state.StateGraph at 0x797cc45bcd70>"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["def add_context(state: State):\n","    print(\"##### ADD CONTEXT #####\")\n","    if messages := state.get(\"messages\", []):\n","        message = messages[-1] # 마지막 message\n","    else:\n","        raise ValueError(\"No message found in input\")\n","\n","    for tool_call in message.tool_calls:\n","        for tool in tools:\n","            if tool.name == tool_call['name']:\n","                describe_str = tool.invoke(tool_call['args'])\n","\n","    # Get context from describe_data tool\n","    print(\"데이터 통계 (context) : \", describe_str[:100])\n","    return {\"context\": describe_str}\n","\n","graph_builder.add_node(\"add_context\", add_context)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sIQeThSCFzv5","executionInfo":{"status":"ok","timestamp":1757986797983,"user_tz":-540,"elapsed":3,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}},"outputId":"a4236858-8632-49d8-dcad-daa19a673245"},"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<langgraph.graph.state.StateGraph at 0x797cc45bcd70>"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["from langgraph.graph import END\n","\n","def guardrail_route(\n","    state: State,\n","):\n","    \"\"\"\n","    Use in the conditional_edge to route to the ToolNode if the last message\n","    has tool calls. Otherwise, route to the end.\n","    \"\"\"\n","    if isinstance(state, list):\n","        ai_message = state[-1]\n","    elif messages := state.get(\"messages\", []):\n","        ai_message = messages[-1]\n","    else:\n","        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n","    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n","        return \"add_context\"\n","    return END\n","\n","\n","graph_builder.add_conditional_edges(\n","    \"chatbot\",\n","    guardrail_route,\n","    {\"add_context\": \"add_context\", END: END},\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nq17Dh_OGW1N","executionInfo":{"status":"ok","timestamp":1757986798001,"user_tz":-540,"elapsed":17,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}},"outputId":"3824fae9-85f4-45f2-9767-2dfe57618658"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<langgraph.graph.state.StateGraph at 0x797cc45bcd70>"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["from pydantic import BaseModel, Field\n","\n","class code(BaseModel):\n","    \"\"\"Schema for code solutions.\"\"\"\n","\n","    prefix: str = Field(description=\"Description of the problem and approach\")\n","    imports: str = Field(description=\"Code block import statements\")\n","    code: str = Field(description=\"Code block not including import statements\")"],"metadata":{"id":"-PO_BFOZHIfY","executionInfo":{"status":"ok","timestamp":1757986798022,"user_tz":-540,"elapsed":20,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["from langchain_core.prompts import ChatPromptTemplate\n","\n","GENERATE_CODE_TEMPLATE = \"\"\"\n","Given the following pandas `describe()` output of a dataset,\n","\n","write a **directly executable Python code** to:\n","1. handle missing values,\n","2. convert categorical columns,\n","3. ...any additional preprocessing needed,\n","4. prepare the dataset for machine learning.\n","\n","Here is the describe result of the dataset:\n","\\n ------- \\n  {context} \\n ------- \\n\n","\n","Do not wrap the code in a function and the response in any backticks or anything else. The code should be written as a flat script, so that it can be run immediately and any errors will be visible during execution.\n","Ensure any code you provide can be executed \\n\n","with all required imports and variables defined. Structure your answer with a description of the code solution. \\n\n","Then list the imports. And finally list the functioning code block.\n","\"\"\"\n","\n","code_gen_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"user\", GENERATE_CODE_TEMPLATE),\n","    ]\n",")"],"metadata":{"id":"8cMVSiuOHO00","executionInfo":{"status":"ok","timestamp":1757986798024,"user_tz":-540,"elapsed":3,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["def generate(state: State):\n","    print(\"##### GENERATING CODE SOLUTION #####\")\n","\n","    context = state[\"context\"]\n","\n","    generated_code = llm_claude.invoke(\n","        code_gen_prompt.format_messages(context=context)\n","    )\n","    code_structurer = llm_gpt.with_structured_output(code)\n","    code_solution = code_structurer.invoke(generated_code.content)\n","\n","    messages = [\n","        (\n","            \"assistant\",\n","            f\"{code_solution.prefix} \\n Imports: {code_solution.imports} \\n Code: {code_solution.code}\",\n","        )\n","    ]\n","\n","    return {\"generation\": code_solution, \"messages\": messages}\n","\n","graph_builder.add_node(\"generate\", generate)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HH-2c1FuHT2D","executionInfo":{"status":"ok","timestamp":1757986798058,"user_tz":-540,"elapsed":32,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}},"outputId":"4885506d-a321-4742-c5aa-370460c670d8"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<langgraph.graph.state.StateGraph at 0x797cc45bcd70>"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["def code_check(state: State):\n","    print(\"##### CHECKING CODE #####\")\n","\n","    code_solution = state[\"generation\"]\n","\n","    imports = code_solution.imports\n","    code = code_solution.code\n","\n","    # Check imports\n","    try:\n","        exec(imports)\n","    except Exception as e:\n","        print(\"---CODE IMPORT CHECK: FAILED---\")\n","        error_message = [(\"user\", f\"Your solution failed the import test: {e}\")]\n","        print(\"에러 메시지 : \", error_message)\n","        return {\n","            \"generation\": code_solution,\n","            \"messages\": error_message,\n","            \"error\": \"yes\",\n","        }\n","\n","    # Check execution\n","    try:\n","        exec(imports + \"\\n\" + code)\n","    except Exception as e:\n","        print(\"---CODE BLOCK CHECK: FAILED---\")\n","        error_message = [(\"user\", f\"Your solution failed the code execution test: {e}\")]\n","        print(\"에러 메시지 : \", error_message)\n","        return {\n","            \"generation\": code_solution,\n","            \"messages\": error_message,\n","            \"error\": \"yes\",\n","        }\n","\n","    # No errors\n","    print(\"---NO CODE TEST FAILURES---\")\n","    return {\n","        \"generation\": code_solution,\n","        \"error\": \"no\",\n","    }\n","\n","graph_builder.add_node(\"code_check\", code_check)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"xqZnN28hHvuo","executionInfo":{"status":"ok","timestamp":1757986798061,"user_tz":-540,"elapsed":10,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}},"outputId":"c86b8924-6b82-4a0c-f7d4-ce8ad0fc644b"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<langgraph.graph.state.StateGraph at 0x797cc45bcd70>"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["from langchain_core.prompts import ChatPromptTemplate\n","\n","reflect_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"\"\"\n","            You are given an error message that occurred while running a Python script, along with the original code that produced the error.\n","            Provide a corrected version of the original code that resolves the issue.\n","            Ensure the code runs without errors and maintains the intended functionality.\"\"\"\n","        ),\n","        (\n","            \"user\",\n","            \"\"\"\n","            --- ERROR MESSAGE ---\n","            {error}\n","            --- ORIGINAL CODE ---\n","            {code_solution}\n","            ----------------------\n","\n","            Ensure any code you provide can be executed \\n\n","            with all required imports and variables defined. Structure your answer with a description of the code solution. \\n\n","            Then list the imports. And finally list the functioning code block.\"\"\",\n","        )\n","    ]\n",")"],"metadata":{"id":"V2sjMT2mH2Yj","executionInfo":{"status":"ok","timestamp":1757986798091,"user_tz":-540,"elapsed":31,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["def reflect(state: State):\n","    print(\"---REFLECTING CODE SOLUTION---\")\n","\n","    error = state[\"messages\"][-1].content\n","    code_solution = state[\"generation\"]\n","    code_solution = f\"{code_solution.prefix} \\n Imports: {code_solution.imports} \\n Code: {code_solution.code}\"\n","\n","    corrected_code = llm_claude.invoke(reflect_prompt.format_messages(error=error, code_solution=code_solution))\n","    code_structurer = llm_gpt.with_structured_output(code)\n","    reflections = code_structurer.invoke(corrected_code.content)\n","    print(\"수정된 코드 : \", reflections)\n","\n","    messages = [\n","        (\n","            \"assistant\",\n","            f\"{reflections.prefix} \\n Imports: {reflections.imports} \\n Code: {reflections.code}\",\n","        )\n","    ]\n","\n","    return {\"generation\": reflections, \"messages\": messages, \"iterations\": state[\"iterations\"] + 1}\n","\n","graph_builder.add_node(\"reflect\", reflect)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zc2UrsYSIiho","executionInfo":{"status":"ok","timestamp":1757986798121,"user_tz":-540,"elapsed":8,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}},"outputId":"edd93afc-01ed-4f22-a659-6ee86d7f023a"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<langgraph.graph.state.StateGraph at 0x797cc45bcd70>"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["max_iterations = 5"],"metadata":{"id":"2ZGX-uuuJZ6H","executionInfo":{"status":"ok","timestamp":1757986798164,"user_tz":-540,"elapsed":17,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["def decide_to_finish(state: State):\n","    error = state[\"error\"]\n","    iterations = state[\"iterations\"]\n","\n","    if error == \"no\" or iterations == max_iterations: # 에러가 없거나 max_iterations에 도달하면 종료\n","        print(\"---DECISION: FINISH---\")\n","        return \"end\"\n","    else:\n","        print(\"---DECISION: RE-TRY SOLUTION---\")\n","        return \"reflect\""],"metadata":{"id":"2_O8eb35JfXU","executionInfo":{"status":"ok","timestamp":1757986798213,"user_tz":-540,"elapsed":26,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["from langgraph.graph import START, END\n","\n","graph_builder.add_edge(START, \"chatbot\")\n","graph_builder.add_edge(\"add_context\", \"generate\")\n","graph_builder.add_edge(\"generate\", \"code_check\")\n","graph_builder.add_conditional_edges(\n","    \"code_check\",\n","    decide_to_finish,\n","    {\n","        \"end\": END,\n","        \"reflect\": \"reflect\"\n","    },\n",")\n","graph_builder.add_edge(\"reflect\", \"code_check\")\n","\n","graph = graph_builder.compile()\n","graph"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":587},"id":"3F6PAk66Jq-O","executionInfo":{"status":"ok","timestamp":1757986798356,"user_tz":-540,"elapsed":141,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}},"outputId":"a1dd92ea-485d-4466-8bf9-2b2ba70a05b9"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<langgraph.graph.state.CompiledStateGraph object at 0x797cc45bc9e0>"],"image/png":"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\n"},"metadata":{},"execution_count":35}]},{"cell_type":"code","source":["question = 'titanic.csv 데이터의 전처리를 부탁해요~'"],"metadata":{"id":"xaYTaREHJ3_P","executionInfo":{"status":"ok","timestamp":1757986798356,"user_tz":-540,"elapsed":4,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["solution = graph.invoke({\"messages\": [('user', question)], 'iterations': 0, 'error': ''})"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xC7P3N9wKGcV","executionInfo":{"status":"ok","timestamp":1757986887505,"user_tz":-540,"elapsed":89151,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}},"outputId":"746bfba7-ef2e-4ee7-b883-99a7793efd9e"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["##### HI ! #####\n","첫번째 LLM 호출 결과 :  content='' additional_kwargs={'tool_calls': [{'id': 'call_82Jcpo1aDVM3eaZldLQnluXv', 'function': {'arguments': '{\"csv\":\"titanic.csv\"}', 'name': 'describe_data'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 282, 'prompt_tokens': 148, 'total_tokens': 430, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 256, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-5-nano-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CGExd3sG5Ia70S9H89R5sxzhO8gvI', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None} id='run--ffc1533e-6677-40ca-b29f-d8cfe577f362-0' tool_calls=[{'name': 'describe_data', 'args': {'csv': 'titanic.csv'}, 'id': 'call_82Jcpo1aDVM3eaZldLQnluXv', 'type': 'tool_call'}] usage_metadata={'input_tokens': 148, 'output_tokens': 282, 'total_tokens': 430, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 256}}\n","##### ADD CONTEXT #####\n","데이터 통계 (context) :  Data: titanic.csv        PassengerId    Survived      Pclass                 Name   Sex         Age \n","##### GENERATING CODE SOLUTION #####\n","##### CHECKING CODE #####\n","---CODE BLOCK CHECK: FAILED---\n","에러 메시지 :  [('user', 'Your solution failed the code execution test: unexpected indent (<string>, line 9)')]\n","---DECISION: RE-TRY SOLUTION---\n","---REFLECTING CODE SOLUTION---\n","수정된 코드 :  prefix=\"You're seeing an unexpected indent error likely due to inconsistent indentation and an incomplete code block. Below is a cleaned, complete Titanic preprocessing pipeline with consistent 4-space indentation and a working baseline logistic regression model.\" imports='import pandas as pd\\nimport numpy as np\\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.impute import SimpleImputer\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import accuracy_score' code='# Load the dataset\\ndf = pd.read_csv(\\'titanic.csv\\')\\n\\nprint(\"Original dataset shape:\", df.shape)\\nprint(\"\\\\nMissing values:\")\\nprint(df.isnull().sum())\\n\\n# Handle missing values\\n# Age: Fill with median\\ndf[\\'Age\\'].fillna(df[\\'Age\\'].median(), inplace=True)\\n\\n# Embarked: Fill with mode (most frequent value)\\ndf[\\'Embarked\\'].fillna(df[\\'Embarked\\'].mode()[0], inplace=True)\\n\\n# Cabin: Create a binary feature for cabin availability and drop original\\ndf[\\'Has_Cabin\\'] = df[\\'Cabin\\'].notna().astype(int)\\ndf.drop(\\'Cabin\\', axis=1, inplace=True)\\n\\n# Create new features\\n# Extract title from Name\\ndf[\\'Title\\'] = df[\\'Name\\'].str.extract(\\' ([A-Za-z]+)\\\\.\\', expand=False)\\n\\n# Group rare titles\\ntitle_mapping = {\\n    \\'Mr\\': \\'Mr\\', \\'Miss\\': \\'Miss\\', \\'Mrs\\': \\'Mrs\\', \\'Master\\': \\'Master\\',\\n    \\'Dr\\': \\'Rare\\', \\'Rev\\': \\'Rare\\', \\'Mlle\\': \\'Miss\\', \\'Major\\': \\'Rare\\',\\n    \\'Col\\': \\'Rare\\', \\'Sir\\': \\'Rare\\', \\'Don\\': \\'Rare\\', \\'Mme\\': \\'Mrs\\',\\n    \\'Jonkheer\\': \\'Rare\\', \\'Lady\\': \\'Rare\\', \\'Capt\\': \\'Rare\\', \\'Countess\\': \\'Rare\\',\\n    \\'Ms\\': \\'Miss\\', \\'Dona\\': \\'Rare\\'\\n}\\ndf[\\'Title\\'] = df[\\'Title\\'].map(title_mapping)\\n# If any Title is unmapped (NaN), assign \\'Rare\\'\\ndf[\\'Title\\'] = df[\\'Title\\'].fillna(\\'Rare\\')\\n\\n# Create family size feature\\ndf[\\'Family_Size\\'] = df[\\'SibSp\\'] + df[\\'Parch\\'] + 1\\n\\n# Create is_alone feature\\ndf[\\'Is_Alone\\'] = (df[\\'Family_Size\\'] == 1).astype(int)\\n\\n# Create age groups\\ndf[\\'Age_Group\\'] = pd.cut(df[\\'Age\\'], bins=[0, 18, 35, 60, 100], labels=[\\'Child\\', \\'Young\\', \\'Adult\\', \\'Senior\\'])\\n\\n# Create fare groups\\ndf[\\'Fare_Group\\'] = pd.cut(df[\\'Fare\\'], bins=[0, 7.91, 14.45, 31, 600], labels=[\\'Low\\', \\'Medium\\', \\'High\\', \\'Very_High\\'])\\n\\n# Drop unnecessary columns\\ncolumns_to_drop = [\\'PassengerId\\', \\'Name\\', \\'Ticket\\']\\ndf.drop(columns=columns_to_drop, inplace=True)\\n\\n# Convert categorical variables to numerical\\ncategorical_columns = [\\'Sex\\', \\'Embarked\\', \\'Title\\', \\'Age_Group\\', \\'Fare_Group\\']\\n\\n# Features and target\\nX = df.drop(\\'Survived\\', axis=1)\\ny = df[\\'Survived\\']\\n\\n# Train-test split\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\\n\\n# Encode categorical features using LabelEncoder (fit on combined train/test to avoid unknowns)\\nlabel_encoders = {}\\nfor col in categorical_columns:\\n    le = LabelEncoder()\\n    combined = pd.concat([X_train[col].astype(str), X_test[col].astype(str)], axis=0).astype(str)\\n    le.fit(combined)\\n    X_train[col] = le.transform(X_train[col].astype(str))\\n    X_test[col] = le.transform(X_test[col].astype(str))\\n    label_encoders[col] = le\\n\\n# Impute any remaining missing values (numeric features may be int/float; after encoding, all are numeric)\\nimputer = SimpleImputer(strategy=\\'median\\')\\nX_train = imputer.fit_transform(X_train)\\nX_test = imputer.transform(X_test)\\n\\n# Scale features\\nscaler = StandardScaler()\\nX_train = scaler.fit_transform(X_train)\\nX_test = scaler.transform(X_test)\\n\\n# Convert back to DataFrame for readability (optional)\\ntrain_cols = [col for col in df.drop(\\'Survived\\', axis=1).columns]\\nX_train = pd.DataFrame(X_train, columns=train_cols)\\nX_test = pd.DataFrame(X_test, columns=train_cols)\\n\\n# Train logistic regression model\\nlogreg = LogisticRegression(max_iter=1000, random_state=42, solver=\\'liblinear\\')\\nlogreg.fit(X_train, y_train)\\n\\ny_pred = logreg.predict(X_test)\\nacc = accuracy_score(y_test, y_pred)\\nprint(\"Validation accuracy:\", acc)\\n'\n","##### CHECKING CODE #####\n","Original dataset shape: (891, 12)\n","\n","Missing values:\n","PassengerId      0\n","Survived         0\n","Pclass           0\n","Name             0\n","Sex              0\n","Age            177\n","SibSp            0\n","Parch            0\n","Ticket           0\n","Fare             0\n","Cabin          687\n","Embarked         2\n","dtype: int64\n","Validation accuracy: 0.7988826815642458\n","---NO CODE TEST FAILURES---\n","---DECISION: FINISH---\n"]},{"output_type":"stream","name":"stderr","text":["<string>:28: SyntaxWarning: invalid escape sequence '\\.'\n","<string>:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","<string>:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n"]}]},{"cell_type":"code","source":["print(solution[\"generation\"].prefix,\"\\n\")\n","print(solution[\"generation\"].imports,\"\\n\")\n","print(solution[\"generation\"].code)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0FnTkjbSKSBq","executionInfo":{"status":"ok","timestamp":1757986930593,"user_tz":-540,"elapsed":23,"user":{"displayName":"Jeongwon Ryu","userId":"18132725682754503053"}},"outputId":"c96d5d74-0522-41b4-bd3e-2a997e0bf741"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["You're seeing an unexpected indent error likely due to inconsistent indentation and an incomplete code block. Below is a cleaned, complete Titanic preprocessing pipeline with consistent 4-space indentation and a working baseline logistic regression model. \n","\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.impute import SimpleImputer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score \n","\n","# Load the dataset\n","df = pd.read_csv('titanic.csv')\n","\n","print(\"Original dataset shape:\", df.shape)\n","print(\"\\nMissing values:\")\n","print(df.isnull().sum())\n","\n","# Handle missing values\n","# Age: Fill with median\n","df['Age'].fillna(df['Age'].median(), inplace=True)\n","\n","# Embarked: Fill with mode (most frequent value)\n","df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n","\n","# Cabin: Create a binary feature for cabin availability and drop original\n","df['Has_Cabin'] = df['Cabin'].notna().astype(int)\n","df.drop('Cabin', axis=1, inplace=True)\n","\n","# Create new features\n","# Extract title from Name\n","df['Title'] = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n","\n","# Group rare titles\n","title_mapping = {\n","    'Mr': 'Mr', 'Miss': 'Miss', 'Mrs': 'Mrs', 'Master': 'Master',\n","    'Dr': 'Rare', 'Rev': 'Rare', 'Mlle': 'Miss', 'Major': 'Rare',\n","    'Col': 'Rare', 'Sir': 'Rare', 'Don': 'Rare', 'Mme': 'Mrs',\n","    'Jonkheer': 'Rare', 'Lady': 'Rare', 'Capt': 'Rare', 'Countess': 'Rare',\n","    'Ms': 'Miss', 'Dona': 'Rare'\n","}\n","df['Title'] = df['Title'].map(title_mapping)\n","# If any Title is unmapped (NaN), assign 'Rare'\n","df['Title'] = df['Title'].fillna('Rare')\n","\n","# Create family size feature\n","df['Family_Size'] = df['SibSp'] + df['Parch'] + 1\n","\n","# Create is_alone feature\n","df['Is_Alone'] = (df['Family_Size'] == 1).astype(int)\n","\n","# Create age groups\n","df['Age_Group'] = pd.cut(df['Age'], bins=[0, 18, 35, 60, 100], labels=['Child', 'Young', 'Adult', 'Senior'])\n","\n","# Create fare groups\n","df['Fare_Group'] = pd.cut(df['Fare'], bins=[0, 7.91, 14.45, 31, 600], labels=['Low', 'Medium', 'High', 'Very_High'])\n","\n","# Drop unnecessary columns\n","columns_to_drop = ['PassengerId', 'Name', 'Ticket']\n","df.drop(columns=columns_to_drop, inplace=True)\n","\n","# Convert categorical variables to numerical\n","categorical_columns = ['Sex', 'Embarked', 'Title', 'Age_Group', 'Fare_Group']\n","\n","# Features and target\n","X = df.drop('Survived', axis=1)\n","y = df['Survived']\n","\n","# Train-test split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n","\n","# Encode categorical features using LabelEncoder (fit on combined train/test to avoid unknowns)\n","label_encoders = {}\n","for col in categorical_columns:\n","    le = LabelEncoder()\n","    combined = pd.concat([X_train[col].astype(str), X_test[col].astype(str)], axis=0).astype(str)\n","    le.fit(combined)\n","    X_train[col] = le.transform(X_train[col].astype(str))\n","    X_test[col] = le.transform(X_test[col].astype(str))\n","    label_encoders[col] = le\n","\n","# Impute any remaining missing values (numeric features may be int/float; after encoding, all are numeric)\n","imputer = SimpleImputer(strategy='median')\n","X_train = imputer.fit_transform(X_train)\n","X_test = imputer.transform(X_test)\n","\n","# Scale features\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# Convert back to DataFrame for readability (optional)\n","train_cols = [col for col in df.drop('Survived', axis=1).columns]\n","X_train = pd.DataFrame(X_train, columns=train_cols)\n","X_test = pd.DataFrame(X_test, columns=train_cols)\n","\n","# Train logistic regression model\n","logreg = LogisticRegression(max_iter=1000, random_state=42, solver='liblinear')\n","logreg.fit(X_train, y_train)\n","\n","y_pred = logreg.predict(X_test)\n","acc = accuracy_score(y_test, y_pred)\n","print(\"Validation accuracy:\", acc)\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"YtuW2YX0L76e"},"execution_count":null,"outputs":[]}]}