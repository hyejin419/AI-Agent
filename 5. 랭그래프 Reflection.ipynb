{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMninz6jSjjpGF7WGjMDgFI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **1. Reflection**\n","\n","Reflection은 에이전트가 스스로 결과를 평가·비판 한 뒤 그 피드백을 상태(state)에 기록하고, 필요하면 수정 루프로 되돌아가 답을 개선하는 설계 패턴입니다. 보통 “작성 노드(답 생성) → 리플렉션 노드(자기평가) → 라우팅(조건부 엣지)”로 구성되며, 리플렉션 노드는 품질 기준(예: 정확성, 근거, 형식)을 점수·코멘트(score, critique)로 남깁니다. 라우터는 이 정보를 읽어 임계값 미달이면 작성 노드로 되감기, 충족하면 종료 노드로 이동합니다. 무한 루프를 막기 위해 max_iters 같은 반복 한도를 두며, 툴 호출과는 별개로 LLM의 자기검토 능력을 활용해 코드 생성, 질의응답, 체인드 리저닝 등의 정확도·일관성을 높이는 데 쓰입니다.\n","\n","<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2Fet5eoq%2FbtsQtfTBoz7%2FAAAAAAAAAAAAAAAAAAAAAM6C44vgBF-5pX8AStDskIMKM2c-gg9io9wsDgxh0NT0%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1759244399%26allow_ip%3D%26allow_referer%3D%26signature%3D9LqfZTAalr4qNMtDaaHHgd6RjCs%253D' width=600>"],"metadata":{"id":"UovVZHAnuUo-"}},{"cell_type":"code","source":["import getpass\n","import os\n","\n","def _set_env(var: str):\n","    if not os.environ.get(var):\n","        os.environ[var] = getpass.getpass(f\"{var}: \")\n","\n","_set_env(\"OPENAI_API_KEY\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":333},"id":"D6F7GwbXudrp","executionInfo":{"status":"error","timestamp":1757981872417,"user_tz":-540,"elapsed":33657,"user":{"displayName":"김혜진","userId":"12819609804489028098"}},"outputId":"b95d3d29-7d2b-41bb-b268-d3c452faa2d8"},"execution_count":1,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"Interrupted by user","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-3069132052.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{var}: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0m_set_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipython-input-3069132052.py\u001b[0m in \u001b[0;36m_set_env\u001b[0;34m(var)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_set_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{var}: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0m_set_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OPENAI_API_KEY\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m   1157\u001b[0m                 \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             )\n\u001b[0;32m-> 1159\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"]}]},{"cell_type":"code","source":["!pip install langchain_openai"],"metadata":{"collapsed":true,"id":"pfYD4bb9vMvU","executionInfo":{"status":"aborted","timestamp":1757981872426,"user_tz":-540,"elapsed":6,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1-1. 가사 생성"],"metadata":{"id":"yn-j8hxXwIFo"}},{"cell_type":"code","source":["from langchain_core.messages import AIMessage, BaseMessage, HumanMessage\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","from langchain_openai import ChatOpenAI\n","\n","prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"당신은 5단락 노래가사를 훌륭하게 작성하는 작사 도우미입니다.\"\n","            \"사용자의 요청에 따라 최고의 가사를 작성하세요.\"\n","            \"사용자가 피드백을 제공할 경우, 이전 시도에서 개선된 수정본을 작성해 응답하세요.\",\n","        ),\n","        MessagesPlaceholder(variable_name=\"messages\"),\n","    ]\n",")\n","\n","llm = ChatOpenAI(model=\"gpt-5-nano\")\n","generate = prompt | llm"],"metadata":{"id":"TPa_UADAwPMH","executionInfo":{"status":"aborted","timestamp":1757981872442,"user_tz":-540,"elapsed":22,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lyric = \"\"   # 빈 문자열 객체를 lyric이라는 변수에 할당. 가사를 담을 변수 선언.\n","request = HumanMessage(\n","    content=\"피자 페퍼로니에 대한 가사를 작성해주세요.\"\n",")\n","for chunk in generate.stream({\"messages\": [request]}):\n","    print(chunk.content, end=\"\")\n","    lyric += chunk.content"],"metadata":{"id":"E65PkDB2wQsq","executionInfo":{"status":"aborted","timestamp":1757981872443,"user_tz":-540,"elapsed":22,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2-2. 가사 개선"],"metadata":{"id":"6unMzaaUwRpp"}},{"cell_type":"code","source":["reflection_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"당신은 가사를 채점하는 작사가입니다. 사용자가 제출한 작사에 대한 비평과 개선 사항을 작성하세요.\"\n","            \"가사의 길이, 깊이, 문체 등을 포함해 구체적인 개선 요청을 제공하세요.\",\n","        ),\n","        MessagesPlaceholder(variable_name=\"messages\"),\n","    ]\n",")\n","reflect = reflection_prompt | llm"],"metadata":{"id":"xN52DvyQwS2c","executionInfo":{"status":"aborted","timestamp":1757981872444,"user_tz":-540,"elapsed":23,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["reflection = \"\"\n","for chunk in reflect.stream({\"messages\": [request, HumanMessage(content=lyric)]}):\n","    print(chunk.content, end=\"\")\n","    reflection += chunk.content"],"metadata":{"id":"wyi1TxJ6wU3e","executionInfo":{"status":"aborted","timestamp":1757981872445,"user_tz":-540,"elapsed":24,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for chunk in generate.stream(\n","    {\"messages\": [request, AIMessage(content=lyric), HumanMessage(content=reflection)]}\n","):\n","    print(chunk.content, end=\"\")"],"metadata":{"id":"25hOp7wgwWuf","executionInfo":{"status":"aborted","timestamp":1757981872445,"user_tz":-540,"elapsed":33839,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2-3. Graph로 Reflection 구현\n","\n","<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FKZUhB%2FbtsQxetHmFz%2FAAAAAAAAAAAAAAAAAAAAAP0EuRkgL4J0CjrSQh0IKSN45ducYKse-WsdmcfUNwRn%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1759244399%26allow_ip%3D%26allow_referer%3D%26signature%3Da5V79BTw4md0u%252FyHl1YhcHNPRpU%253D'>"],"metadata":{"id":"M31pciSYwvi_"}},{"cell_type":"code","source":["!pip install langgraph"],"metadata":{"collapsed":true,"id":"pkk9CpXhwzre","executionInfo":{"status":"aborted","timestamp":1757981872479,"user_tz":-540,"elapsed":3,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from typing import Annotated\n","from typing_extensions import TypedDict\n","\n","from langgraph.graph import END, StateGraph, START\n","from langgraph.graph.message import add_messages\n","from langgraph.checkpoint.memory import MemorySaver\n","\n","\n","class State(TypedDict):\n","    messages: Annotated[list, add_messages]"],"metadata":{"id":"ZCrFHAtWw0wd","executionInfo":{"status":"aborted","timestamp":1757981872489,"user_tz":-540,"elapsed":12,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generation_node(state: State) -> State:\n","    return {\"messages\": [generate.invoke(state[\"messages\"])]}  # state에서 messages(Annotated[list, add_messages])를 꺼내서 \"messages\"에 저장."],"metadata":{"id":"9kUktc6Hw2aT","executionInfo":{"status":"aborted","timestamp":1757981872490,"user_tz":-540,"elapsed":13,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def reflection_node(state: State) -> State:\n","    cls_map = {\"ai\": AIMessage, \"human\": HumanMessage}\n","\n","    # 첫번째 사용자 요청 + 생성메시지 (reflection_node's input)\n","    # 첫번째 사용자 요청 + 생성메시지 + 피드백메시지 (generation_node's input)\n","    # 첫번째 사용자 요청 + 생성메시지 + 피드백메시지 + 수정된 생성메시지 (reflection_node's input)\n","    # 첫번째 사용자 요청 + 생성메시지 + 피드백메시지 + 수정된 생성메시지 + 피드백메시지 (generation_node's input)\n","    # ...\n","    translated = [state[\"messages\"][0]] + [\n","        cls_map[msg.type](content=msg.content) for msg in state[\"messages\"][1:]  # 돌아온 값에서 값을 꺼냄. 1번 이후 값 중에서 타입과 컨텐트를 꺼내 translated에 저장.\n","    ]\n","    # translated = [state[\"messages\"][0]] + [\n","    #     cls_map[msg.type](content=msg.content) for msg in state[\"messages\"][-2:]\n","    # ]\n","    res = reflect.invoke(translated)\n","\n","    return {\"messages\": [HumanMessage(content=res.content)]}  # res의 content를 꺼냄"],"metadata":{"id":"4R-YRDvkw3jt","executionInfo":{"status":"aborted","timestamp":1757981872491,"user_tz":-540,"elapsed":14,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["graph_builder = StateGraph(State)\n","graph_builder.add_node(\"generate\", generation_node)\n","graph_builder.add_node(\"reflect\", reflection_node)\n","graph_builder.add_edge(START, \"generate\")"],"metadata":{"id":"JlvAm-Bow4gv","executionInfo":{"status":"aborted","timestamp":1757981872497,"user_tz":-540,"elapsed":19,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from typing import Literal\n","from langgraph.graph import END\n","\n","def should_continue(state: State) -> Literal[\"reflect\", END]:  # reflect, END 둘 중 하나로 가게 함.\n","    if len(state[\"messages\"]) > 6:\n","        return END\n","    return \"reflect\"\n","\n","\n","graph_builder.add_conditional_edges(\"generate\", should_continue)"],"metadata":{"id":"CbmtB_q_w5iD","executionInfo":{"status":"aborted","timestamp":1757981872498,"user_tz":-540,"elapsed":20,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["graph_builder.add_edge(\"reflect\", \"generate\")"],"metadata":{"id":"o6EijB1Dw6b_","executionInfo":{"status":"aborted","timestamp":1757981872499,"user_tz":-540,"elapsed":33884,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["memory = MemorySaver()\n","graph = graph_builder.compile(checkpointer=memory)\n","graph"],"metadata":{"id":"Kk764AQnw7TZ","executionInfo":{"status":"aborted","timestamp":1757981872499,"user_tz":-540,"elapsed":33882,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["config = {\"configurable\": {\"thread_id\": \"1\"}}"],"metadata":{"id":"Egh56JBsw7_B","executionInfo":{"status":"aborted","timestamp":1757981872500,"user_tz":-540,"elapsed":33883,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for event in graph.stream(\n","    {\n","        \"messages\": [\n","            HumanMessage(\n","                content=\"이별에 대한 가사를 작성해주세요.\"\n","            )\n","        ],\n","    },\n","    config,\n","):\n","    print(event)\n","    print(\"---\")"],"metadata":{"id":"d2e04FdVw82v","executionInfo":{"status":"aborted","timestamp":1757981872500,"user_tz":-540,"elapsed":33880,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["state = graph.get_state(config)\n","state"],"metadata":{"collapsed":true,"id":"s_cO8WY0w9jb","executionInfo":{"status":"aborted","timestamp":1757981872501,"user_tz":-540,"elapsed":33879,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ChatPromptTemplate.from_messages(state.values[\"messages\"]).pretty_print()"],"metadata":{"id":"HA7f44RUw-h-","executionInfo":{"status":"aborted","timestamp":1757981872501,"user_tz":-540,"elapsed":33877,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **2. Reflextion 구현**\n","\n","[“Reflexion: Language Agents with Verbal Reinforcement Learning”](https://arxiv.org/abs/2303.11366)은, 2023년 3월 20일 최초 제출, 2023년 10월 10일 v4로 개정된 논문입니다. 저자는 Noah Shinn 외 5명이고, 핵심 내용은 언어 에이전트가 스스로 언어적 피드백(반성문)을 생성·메모리에 저장해 다음 시도에 반영함으로써 성능을 높이는 프레임워크를 제안했다는 점입니다. HumanEval 등에서 유의미한 향상을 보고합니다.\n","\n","<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2Fdzon1Q%2FbtsQxdO7zsM%2FAAAAAAAAAAAAAAAAAAAAAIv8GnJo2Z7lQar4RlJWoaap2PH03wadiph8ot4leqkE%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1759244399%26allow_ip%3D%26allow_referer%3D%26signature%3D8FwKXg927T0ByPpvHRMXDCmMW6w%253D'>"],"metadata":{"id":"8GsYKuC9xAAF"}},{"cell_type":"markdown","source":["- Actor (LM): 실제 행동(답안 작성, 코드 생성 등)을 내는 언어모델입니다.\n","- Evaluator (LM): Actor가 낸 결과를 내부적으로 평가합니다(정확성·형식·테스트 통과 여부 판단 등).\n","- Self-reflection (LM): 평가 결과를 바탕으로 “다음에는 이렇게 고치자” 같은 반성문(Reflective text)을 만들어 냅니다.\n","- Trajectory (short-term memory): 이번 시도에서의 행동/관찰 기록(a₀, o₀, …)을 담는 단기 메모리입니다.\n","- Experience (long-term memory): 누적된 반성문을 쌓아두는 장기 메모리(mem)입니다. 이후 시도에서 프롬프트에 이 기억을 넣어 같은 실수를 반복하지 않게 합니다.\n","- Environment: 외부에서 관찰/보상(예: 유닛 테스트의 통과/실패, 웹툴의 응답 등)을 제공합니다. 외부 피드백이 있으면 Evaluator의 판단과 함께 사용됩니다.\n","\n","<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2Fmii1M%2FbtsQzJFXs6L%2FAAAAAAAAAAAAAAAAAAAAABlDou97baB3Ry75PiiSdFP4Aml0fM58iNNa5PCw8tAm%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1759244399%26allow_ip%3D%26allow_referer%3D%26signature%3D4AJfc3vS%252BrrpVpN%252BWzMG7%252BP%252FfxE%253D' width=600>"],"metadata":{"id":"rhNGluDd4K1x"}},{"cell_type":"code","source":["import os\n","import getpass\n","\n","def _set_env(var: str):\n","    if not os.environ.get(var):\n","        os.environ[var] = getpass.getpass(f\"{var}: \")\n","\n","_set_env(\"TAVILY_API_KEY\")"],"metadata":{"id":"KgKSqrLxxEBr","executionInfo":{"status":"aborted","timestamp":1757981872502,"user_tz":-540,"elapsed":33878,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_openai import ChatOpenAI\n","\n","llm = ChatOpenAI(model=\"gpt-5-nano\")"],"metadata":{"id":"9V2fA8cl4PMu","executionInfo":{"status":"aborted","timestamp":1757981872503,"user_tz":-540,"elapsed":33879,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install langchain_community"],"metadata":{"collapsed":true,"id":"CiS6mXWQ4QK8","executionInfo":{"status":"aborted","timestamp":1757981872503,"user_tz":-540,"elapsed":33878,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install langchain-tavily"],"metadata":{"collapsed":true,"id":"ptFMGg1B4Q78","executionInfo":{"status":"aborted","timestamp":1757981872512,"user_tz":-540,"elapsed":33884,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_tavily import TavilySearch\n","\n","tavily_tool = TavilySearch(max_results=5)"],"metadata":{"id":"zkgBvr9m8bfZ","executionInfo":{"status":"aborted","timestamp":1757981872516,"user_tz":-540,"elapsed":33887,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**2-1. 필요한 데이터 클래스 정의**"],"metadata":{"id":"tbr2ozWZ8eUI"}},{"cell_type":"code","source":["# Reflection - 놓친것 / 불필요한 것\n","from langchain_core.messages import HumanMessage, ToolMessage\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","from pydantic import BaseModel, Field\n","\n","class Reflection(BaseModel):\n","    missing: str = Field(description=\"누락되거나 부족한 부분에 대한 비평\")\n","    superfluous: str = Field(description=\"불필요한 부분에 대한 비평\")"],"metadata":{"id":"8z9W5TLS8dDw","executionInfo":{"status":"aborted","timestamp":1757981872519,"user_tz":-540,"elapsed":33890,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# AnswerQuestion - 답변 / 답변에 대한 반성 / 개선하기 위한 검색 쿼리\n","class AnswerQuestion(BaseModel):\n","    answer: str = Field(description=\"질문에 대한 10문장 이내의 자세한 답변\")\n","    search_queries: list[str] = Field(\n","        description=\"현재 답변에 대한 비평을 해결하기 위한 추가 조사를 위한 1~3개의 웹 검색 쿼리\"\n","    )\n","    reflection: Reflection = Field(description=\"답변에 대한 자기반성 내용\")"],"metadata":{"id":"coFoJnNg8lfj","executionInfo":{"status":"aborted","timestamp":1757981872520,"user_tz":-540,"elapsed":33891,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Responder - 구조화된 출력을 위한 답변기\n","class Responder:\n","    def __init__(self, runnable):\n","        self.runnable = runnable # Chain\n","\n","    def respond(self, state: dict):\n","        response = self.runnable.invoke(\n","            {\"messages\": state[\"messages\"]}\n","        )\n","        return {\"messages\": response}"],"metadata":{"id":"X6p985hU8oLW","executionInfo":{"status":"aborted","timestamp":1757981872521,"user_tz":-540,"elapsed":33892,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**2-2. 초기 답변기 만들기 (Initial responder)**"],"metadata":{"id":"MwykbM098qQH"}},{"cell_type":"code","source":["# 초기 답변을 위한 Chain 생성 -출력 스키마를 도구로 사용\n","import datetime\n","\n","actor_prompt_template = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"\"\"당신은 전문 연구자입니다.\n","\n","            1. {first_instruction}\n","            2. <Reflect> 생성한 답변을 다시 되돌아보고 개선할 수 있도록 비판하세요.\n","            3. <Recommend search queries> 답변의 질을 높이기 위해 추가적으로 조사해야 할 정보에 대한 웹 검색 쿼리를 추천하세요.\"\"\",\n","        ),\n","        MessagesPlaceholder(variable_name=\"messages\"),\n","        (\n","            \"user\",\n","            \"\\n\\n<Reflect> 사용자 원래 질문과 지금까지의 행동을 되돌아보세요.\"\n","        ),\n","    ]\n",")\n","\n","initial_answer_chain = actor_prompt_template.partial(\n","    first_instruction=\"질문에 대한 10문장 이내의 자세한 답변을 제공해주세요.\", # 초기 답변\n",") | llm.bind_tools(tools=[AnswerQuestion], tool_choice=\"any\")"],"metadata":{"id":"hFrBqjwH8tF7","executionInfo":{"status":"aborted","timestamp":1757981872521,"user_tz":-540,"elapsed":33892,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["⋇ [구조화 출력을 위해 스키마를 도구로 사용하는 방법](https://python.langchain.com/docs/concepts/structured_outputs/#using-tool-calling)"],"metadata":{"id":"YMhH8lJq9kUD"}},{"cell_type":"code","source":["llm_with_tool = llm.bind_tools(tools=[AnswerQuestion], tool_choice=\"any\")\n","response = llm_with_tool.invoke([HumanMessage(content=\"AI Agent가 무엇인가요?\")])\n","print(response)"],"metadata":{"id":"7_9HU0D-9Qmj","executionInfo":{"status":"aborted","timestamp":1757981872522,"user_tz":-540,"elapsed":33890,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response.tool_calls[0]['args']"],"metadata":{"id":"ikyF_XZV9RT5","executionInfo":{"status":"aborted","timestamp":1757981872522,"user_tz":-540,"elapsed":33888,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["first_responder = Responder(runnable=initial_answer_chain)"],"metadata":{"id":"ZZk1k-Ap9SAZ","executionInfo":{"status":"aborted","timestamp":1757981872523,"user_tz":-540,"elapsed":33889,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["example_question = \"AI Agent가 무엇인가요?\"\n","initial = first_responder.respond(\n","    {\"messages\": [HumanMessage(content=example_question)]}\n",")\n","initial\n","# 검색에 의해 메시지를 출력함. (content가 비어있음.)"],"metadata":{"id":"BSwMCO8c9S8h","executionInfo":{"status":"aborted","timestamp":1757981872523,"user_tz":-540,"elapsed":33887,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# tool 호출 결과 확인 (AnswerQuestion 에 맞춰 출력 생성)\n","initial[\"messages\"].tool_calls[0][\"args\"]"],"metadata":{"id":"ho8ToZ5M9wY6","executionInfo":{"status":"aborted","timestamp":1757981872574,"user_tz":-540,"elapsed":33937,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**2-3. 수정 단계(Revision)**"],"metadata":{"id":"zfKwFFQo9yhT"}},{"cell_type":"code","source":["class ReviseAnswer(AnswerQuestion):\n","    # 답변 > 자기 반성 > 근거 인용 > 검색 제안\n","    \"\"\"Revise your original answer to your question. Provide an answer, reflection,\n","\n","    cite your reflection with references, and finally\n","    add search queries to improve the answer.\"\"\"\n","\n","    references: list[str] = Field(\n","        description=\"업데이트된 답변에 사용된 인용 출처\"\n","    )"],"metadata":{"id":"csCjVcpd90Ow","executionInfo":{"status":"aborted","timestamp":1757981872575,"user_tz":-540,"elapsed":33938,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["revise_instructions = \"\"\"이전 답변을 새로운 정보를 바탕으로 수정하세요.\n","- 이전 비평 내용을 활용해 중요한 정보를 추가해야 합니다.\n","  - 수정된 답변에는 반드시 숫자로 된 인용 표시를 포함하여 검증 가능하도록 해야 합니다.\n","  - 답변 하단에 \"참고문헌\" 섹션을 추가하세요 (이 부분은 단어 수 제한에 포함되지 않습니다). 형식은 다음과 같습니다:\n","    - [1] https://example.com\n","    - [2] https://example.com\n","\n","- 이전 비평 내용을 바탕으로 불필요한 정보를 제거하고, 최종 답변은 반드시 200자를 넘지 않도록 하세요.\n","\"\"\"\n","\n","\n","revision_chain = actor_prompt_template.partial(\n","    first_instruction=revise_instructions,\n",") | llm.bind_tools(tools=[ReviseAnswer], tool_choice=\"any\")\n","\n","\n","revisor = Responder(runnable=revision_chain)\n","revisor  # 객체 자체"],"metadata":{"id":"Nb9Pg2c992fG","executionInfo":{"status":"aborted","timestamp":1757981872576,"user_tz":-540,"elapsed":33937,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 초기답변에서 생성한 웹검색 쿼리를 Tool 실행한 결과를 함께 입력\n","import json\n","\n","revised = revisor.respond(\n","    {\n","        \"messages\": [\n","            HumanMessage(content=example_question),\n","            initial[\"messages\"],\n","            ToolMessage(\n","                tool_call_id=initial['messages'].additional_kwargs['tool_calls'][0]['id'],  # keywordarguments\n","                content=json.dumps(\n","                    tavily_tool.invoke(\n","                        {\n","                            \"query\": initial[\"messages\"].tool_calls[0][\"args\"]['search_queries'][0]\n","                        }\n","                    )\n","                ),\n","            ),\n","        ]\n","    }\n",")"],"metadata":{"id":"K2adYdJH93PP","executionInfo":{"status":"aborted","timestamp":1757981872576,"user_tz":-540,"elapsed":33936,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<img src='https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdna%2FnMKU1%2FbtsQwRziUZl%2FAAAAAAAAAAAAAAAAAAAAAASlhE2QFrMfwp2mVpfbJqW1PV9_JrnKxfrPSLouN6QH%2Fimg.png%3Fcredential%3DyqXZFxpELC7KVnFOS48ylbz2pIh7yKj8%26expires%3D1759244399%26allow_ip%3D%26allow_referer%3D%26signature%3Dmo7gpz9i5fHpvBdpj4E4qkNltG4%253D'>"],"metadata":{"id":"Mpvx5G0E97KI"}},{"cell_type":"code","source":["revised[\"messages\"]"],"metadata":{"id":"cViv3JfN98wB","executionInfo":{"status":"aborted","timestamp":1757981872577,"user_tz":-540,"elapsed":33936,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["revised[\"messages\"].tool_calls"],"metadata":{"id":"1ergvMFG9-Sd","executionInfo":{"status":"aborted","timestamp":1757981872577,"user_tz":-540,"elapsed":33934,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**2-4. 웹검색을 위한 툴 노드 생성**"],"metadata":{"id":"yy2Pmpvg9_D4"}},{"cell_type":"code","source":["tavily_tool.batch(\n","    [\n","        {\"query\": initial[\"messages\"].tool_calls[0][\"args\"]['search_queries'][0]}\n","    ]\n",")"],"metadata":{"id":"Er51aCgN-AVm","executionInfo":{"status":"aborted","timestamp":1757981872578,"user_tz":-540,"elapsed":33933,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_core.tools import StructuredTool\n","\n","from langgraph.prebuilt import ToolNode\n","\n","\n","def run_queries(search_queries: list[str], **kwargs):\n","    \"\"\"Run the generated queries.\"\"\"\n","    return tavily_tool.batch([{\"query\": query} for query in search_queries])\n","\n","\n","tool_node = ToolNode(\n","    [\n","        StructuredTool.from_function(run_queries, name=AnswerQuestion.__name__),\n","        StructuredTool.from_function(run_queries, name=ReviseAnswer.__name__),\n","    ]\n",")"],"metadata":{"id":"Sc1-fkDX-Ckn","executionInfo":{"status":"aborted","timestamp":1757981872578,"user_tz":-540,"elapsed":33933,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**2-5. 그래프 생성하기**"],"metadata":{"id":"3cC_MBHI-DoP"}},{"cell_type":"code","source":["from langgraph.graph import END, StateGraph, START\n","from langgraph.graph.message import add_messages\n","from typing import Annotated\n","from typing_extensions import TypedDict\n","\n","\n","class State(TypedDict):\n","    messages: Annotated[list, add_messages]"],"metadata":{"id":"VVcmpKpL-FQN","executionInfo":{"status":"aborted","timestamp":1757981872579,"user_tz":-540,"elapsed":33934,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["MAX_ITERATIONS = 5\n","graph_builder = StateGraph(State)\n","graph_builder.add_node(\"draft\", first_responder.respond)\n","\n","graph_builder.add_node(\"execute_tools\", tool_node) # 웹 검색 진행\n","graph_builder.add_node(\"revise\", revisor.respond)\n","\n","graph_builder.add_edge(\"draft\", \"execute_tools\")\n","graph_builder.add_edge(\"execute_tools\", \"revise\")"],"metadata":{"id":"1nIXiTV3-HT8","executionInfo":{"status":"aborted","timestamp":1757981872579,"user_tz":-540,"elapsed":33932,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def _get_num_iterations(state: list):\n","    i = 0\n","    for m in state[::-1]:\n","        if m.type not in {\"tool\", \"ai\"}:\n","            break\n","        i += 1\n","    return i\n","\n","\n","def event_loop(state: list):\n","    num_iterations = _get_num_iterations(state[\"messages\"])\n","    if num_iterations > MAX_ITERATIONS:\n","        return END\n","    return \"execute_tools\"\n","\n","\n","graph_builder.add_conditional_edges(\"revise\", event_loop, [\"execute_tools\", END])\n","graph_builder.add_edge(START, \"draft\")\n","graph = graph_builder.compile()\n","graph"],"metadata":{"id":"Iw0EjOv9-JbG","executionInfo":{"status":"aborted","timestamp":1757981872580,"user_tz":-540,"elapsed":33932,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["events = graph.stream(\n","    {\"messages\": [HumanMessage(content=\"AI Agent가 무엇인가요?\")]},\n","    stream_mode=\"values\",\n",")\n","for i, step in enumerate(events):\n","    print(f\"Step {i}\")\n","    step[\"messages\"][-1].pretty_print()"],"metadata":{"id":"qNT8rwHW-Lc0","executionInfo":{"status":"aborted","timestamp":1757981872580,"user_tz":-540,"elapsed":33929,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **3. Plan & Excute**"],"metadata":{"id":"P5PuAScTIQBj"}},{"cell_type":"code","source":["import getpass\n","import os\n","\n","\n","def _set_env(var: str):\n","    if not os.environ.get(var):\n","        os.environ[var] = getpass.getpass(f\"{var}: \")\n","\n","\n","_set_env(\"OPENAI_API_KEY\")\n","_set_env(\"TAVILY_API_KEY\")"],"metadata":{"id":"3HaeVBmRITbf","executionInfo":{"status":"aborted","timestamp":1757981872581,"user_tz":-540,"elapsed":33930,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install langchain_community"],"metadata":{"collapsed":true,"id":"55LTfrIfItNM","executionInfo":{"status":"aborted","timestamp":1757981872581,"user_tz":-540,"elapsed":33928,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_community.tools.tavily_search import TavilySearchResults"],"metadata":{"id":"xR2FEtkfIuCT","executionInfo":{"status":"aborted","timestamp":1757981872582,"user_tz":-540,"elapsed":33929,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["search_tool = TavilySearchResults(max_results=3)\n","tools = [search_tool]"],"metadata":{"id":"HbimjpyhI6hX","executionInfo":{"status":"aborted","timestamp":1757981872582,"user_tz":-540,"elapsed":33928,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install langchain_openai"],"metadata":{"collapsed":true,"id":"MJ45jf2bJBv1","executionInfo":{"status":"aborted","timestamp":1757981872583,"user_tz":-540,"elapsed":33927,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install langgraph"],"metadata":{"collapsed":true,"id":"m33uqSBKJHW5","executionInfo":{"status":"aborted","timestamp":1757981872591,"user_tz":-540,"elapsed":33934,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ReAct 패턴\n","# 추론 > 행동 > 관찰 > 답변, 자동으로 생성\n","from langchain_openai import ChatOpenAI\n","from langgraph.prebuilt import create_react_agent\n","\n","llm = ChatOpenAI(model=\"gpt-5-nano\")\n","prompt = \"You are a helpful assistant.\"\n","plan_executor = create_react_agent(llm, tools, prompt=prompt)\n","plan_executor"],"metadata":{"id":"FJ8WepJBJJka","executionInfo":{"status":"aborted","timestamp":1757981872598,"user_tz":-540,"elapsed":33939,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plan_executor.invoke({'messages': [('user', '2025년 한국의 최저시급은 얼마입니까?')]})\n","\n","#  AIMessage(content='', : 검색 에이전트를 활용했음을 알 수 있다."],"metadata":{"id":"LFZF-c4VJTFo","executionInfo":{"status":"aborted","timestamp":1757981872599,"user_tz":-540,"elapsed":33938,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pydantic import BaseModel, Field\n","from typing import List"],"metadata":{"id":"uYAkgXH4KrQ4","executionInfo":{"status":"aborted","timestamp":1757981872599,"user_tz":-540,"elapsed":33938,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Plan(BaseModel):\n","    \"\"\"Plan to follow in future\"\"\"\n","    steps: List[str] = Field(\n","        description=\"different steps to follow, should be in sorted order\"\n","    )"],"metadata":{"id":"E5xq01HWKpbS","executionInfo":{"status":"aborted","timestamp":1757981872600,"user_tz":-540,"elapsed":33939,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","from langchain_core.messages import AIMessage, BaseMessage, HumanMessage"],"metadata":{"id":"9kWEiNJxLDVM","executionInfo":{"status":"aborted","timestamp":1757981872607,"user_tz":-540,"elapsed":33945,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["planner_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"\"\"For the given objective, come up with a simple step by step plan. \\\n","            This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n","            The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\"\"\",\n","        ),\n","        MessagesPlaceholder(variable_name=\"messages\"),\n","    ]\n",")\n","planner = planner_prompt | llm.with_structured_output(Plan)"],"metadata":{"id":"6KIgRtwELF18","executionInfo":{"status":"aborted","timestamp":1757981872608,"user_tz":-540,"elapsed":33946,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plan_result = planner.invoke(\n","    {\n","        \"messages\": [HumanMessage(\n","            content=\"2025년 한국에서 개봉한 영화 중 가장 흥행한 영화는 무엇인가요?\",\n","        )]\n","    }\n",")"],"metadata":{"id":"DErpuO-xLIl1","executionInfo":{"status":"aborted","timestamp":1757981872609,"user_tz":-540,"elapsed":33947,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["replanner_prompt = ChatPromptTemplate.from_template(\n","    \"\"\"For the given objective, come up with a simple step by step plan. \\\n","    This plan should involve individual tasks, that if executed correctly will yield the correct answer. Do not add any superfluous steps. \\\n","    The result of the final step should be the final answer. Make sure that each step has all the information needed - do not skip steps.\n","    Your objective was this:\n","    {input}\n","    Your original plan was this:\n","    {plan}\n","    You have currently done the follow steps:\n","    {past_steps}\n","    Update your plan accordingly.\n","    If no more steps are needed and you can return to the user, then respond with that.\n","    Otherwise, fill out the plan. Only add steps to the plan that still NEED to be done.\n","    Do not return previously done steps as part of the plan.\"\"\"\n",")"],"metadata":{"id":"X-PdISDYMA5x","executionInfo":{"status":"aborted","timestamp":1757981872610,"user_tz":-540,"elapsed":33948,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from typing import Union\n","class Response(BaseModel):\n","    \"\"\"Response to user.\"\"\"\n","    response: str\n","class Act(BaseModel):\n","    \"\"\"Action to perform.\"\"\"\n","    action: Union[Response, Plan] = Field(\n","        description=\"Action to perform. If you want to respond to user, use Response. \"\n","        \"If you need to further use tools to get the answer, use Plan.\"\n","    )"],"metadata":{"id":"FVoYyfqXMh8b","executionInfo":{"status":"aborted","timestamp":1757981872610,"user_tz":-540,"elapsed":33948,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["replanner = replanner_prompt | llm.with_structured_output(Act)"],"metadata":{"id":"FDBb9nmkM28R","executionInfo":{"status":"aborted","timestamp":1757981872611,"user_tz":-540,"elapsed":33949,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import operator\n","from typing import Annotated, List, Tuple\n","from typing_extensions import TypedDict\n","class PlanExecute(TypedDict):\n","    input: str\n","    plan: List[str]\n","    past_steps: Annotated[List[Tuple], operator.add]\n","    response: str"],"metadata":{"id":"Fx2tRaYSNdq7","executionInfo":{"status":"aborted","timestamp":1757981872612,"user_tz":-540,"elapsed":33949,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 계획 생성\n","def plan_step(state: PlanExecute):\n","    plan = planner.invoke({\"messages\": [(\"user\", state[\"input\"])]})\n","    return {\"plan\": plan.steps}"],"metadata":{"id":"kVwbGZTlM9Ud","executionInfo":{"status":"aborted","timestamp":1757981872613,"user_tz":-540,"elapsed":33950,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def execute_step(state: PlanExecute):\n","    plan = state[\"plan\"]\n","    plan_str = \"\\n\".join(f\"{i+1}. {step}\" for i, step in enumerate(plan))\n","    task = plan[0]\n","    task_formatted = f\"\"\"For the following plan:\n","    {plan_str}\\n\\nYou are tasked with executing step {1}, {task}.\"\"\"\n","    agent_response = plan_executor.invoke(\n","        {\"messages\": [(\"user\", task_formatted)]}\n","    )\n","    return {\n","        \"past_steps\": [(task, agent_response[\"messages\"][-1].content)], # 실행 완료한 계획과 결과 저장\n","    }"],"metadata":{"id":"Rmv85zkNNlfT","executionInfo":{"status":"aborted","timestamp":1757981872613,"user_tz":-540,"elapsed":33950,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 계획 수정\n","def replan_step(state: PlanExecute):\n","    output = replanner.invoke(state)\n","    if isinstance(output.action, Response): # 답변이 바로 가능한 상태\n","        return {\"response\": output.action.response}\n","    else:\n","        return {\"plan\": output.action.steps}"],"metadata":{"id":"iQ2L5bVEOElS","executionInfo":{"status":"aborted","timestamp":1757981872614,"user_tz":-540,"elapsed":33951,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langgraph.graph import END\n","def should_end(state: PlanExecute):\n","    if \"response\" in state and state[\"response\"]:\n","        return END\n","    else:\n","        return \"agent\""],"metadata":{"id":"SDQSxCFnO-6_","executionInfo":{"status":"aborted","timestamp":1757981872614,"user_tz":-540,"elapsed":33951,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langgraph.graph import StateGraph, START\n","graph_builder = StateGraph(PlanExecute)\n","graph_builder.add_node(\"planner\", plan_step)\n","graph_builder.add_node(\"agent\", execute_step)\n","graph_builder.add_node(\"replan\", replan_step)\n","graph_builder.add_edge(START, \"planner\")\n","graph_builder.add_edge(\"planner\", \"agent\")\n","graph_builder.add_edge(\"agent\", \"replan\")\n","graph_builder.add_conditional_edges(\n","    \"replan\",\n","    should_end,\n","    [\"agent\", END],\n",")\n","graph = graph_builder.compile()"],"metadata":{"id":"mlp-BaE-PDWB","executionInfo":{"status":"aborted","timestamp":1757981872615,"user_tz":-540,"elapsed":33952,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["graph"],"metadata":{"id":"FMBwWqfVPEO4","executionInfo":{"status":"aborted","timestamp":1757981872615,"user_tz":-540,"elapsed":33949,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["config = {'recursion_linit': 50}\n","inputs = {'input': '2024년 노벨문학상 수상자의 출신국가는 어디인가요?'}\n","for event in graph.stream(inputs, config=config, stream_mode='values'):\n","    for k, v in event.items():\n","        print(k, v)\n","    print('*' * 50)"],"metadata":{"id":"yzvyqxu2PEHd","executionInfo":{"status":"aborted","timestamp":1757981872616,"user_tz":-540,"elapsed":33948,"user":{"displayName":"김혜진","userId":"12819609804489028098"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **4. 코드 수정을 반복하는 데이터 전처리 Agent**"],"metadata":{"id":"WKbF_M8TPaSp"}},{"cell_type":"markdown","source":["**클로드**\n","\n","클로드(Claude)는 앤트로픽(Anthropic)에서 개발한 대규모 언어 모델(LLM) 기반의 인공지능 챗봇으로, 사람과의 대화, 글쓰기, 요약, 코드 작성 등 다양한 작업을 수행할 수 있는 생성형 AI입니다. 이름은 인공지능의 선구자 클로드 섀넌(Claude Shannon)에서 따왔으며, “헌宪법 기반 AI(constitutional AI)” 접근법을 적용해 안전성과 투명성을 강화한 것이 특징입니다. 즉, 인간의 직접적인 지시보다는 미리 정해둔 원칙과 가이드라인을 통해 스스로 출력을 조율하도록 설계되었기 때문에, 사용자가 안심하고 활용할 수 있는 대화형 AI라는 점에서 주목받고 있습니다."],"metadata":{"id":"qLZEGNQ73_rZ"}},{"cell_type":"code","source":["# titanic.csv 파일 업로드 후 실행 (국비 폴더 안에 저장해 놓음.)\n","# 클로드 api key 필요 (유료)"],"metadata":{"id":"37Ra3Jr4-cYd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import getpass\n","import os\n","\n","def _set_env(var: str):\n","    if not os.environ.get(var):\n","        os.environ[var] = getpass.getpass(f\"{var}: \")\n","_set_env(\"OPENAI_API_KEY\")\n","_set_env(\"ANTHROPIC_API_KEY\")  # 클로드 api key"],"metadata":{"id":"bcyXXjIi4wsF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_core.tools import tool\n","import pandas as pd"],"metadata":{"id":"-2YKCO-r7ED2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["@tool\n","def describe_data(csv: str) -> str:\n","    \"\"\"Describe the date column in the dataframe.\n","    Args:\n","        csv: csv data path string\n","    \"\"\""],"metadata":{"id":"7T9TPWI47E0V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tools = [describe_data]"],"metadata":{"id":"afyUrtNk7HkC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install langchain_openai"],"metadata":{"id":"hrrY0GeI7iW1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install langchain_anthropic"],"metadata":{"id":"D3TFqStt7sk-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_openai import ChatOpenAI\n","from langchain_anthropic import ChatAnthropic\n","\n","llm_gpt = ChatOpenAI(model=\"gpt-5-nano\")\n","llm_with_tools = llm_gpt.bind_tools(tools, tool_choice=\"any\")"],"metadata":{"id":"8IVyOiBe7438"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response = llm_with_tools.invoke(\n","    \"https://raw.githubusercontent.com/pycaret/pycaret/master/datasets/diabetes.csv 이 데이터의 전처리를 해주세요.\"\n",")"],"metadata":{"id":"je5kKtPt76Hc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response.tool_calls[0]"],"metadata":{"id":"l-geFXA59pxe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["response.too_calls[0]['args']"],"metadata":{"id":"9L7LNJjG9srE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tool_result = describe_data.invoke(response.tool_calls[0]['args'])\n","print(tool_result)"],"metadata":{"id":"0vo42wGu_-aI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generated_code = llm_claude.invoke(\n","    code_gen_prompt.format_messages(context=tool_result)\n",")\n","print(\"generated_code\", generated_code)  # 출력 결과를 vscode에서 확인해보자."],"metadata":{"id":"RFM6rTxhAPTb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["code_structurer = llm_gpt.with_structured_output(code)\n","code_solution = code_structurer.invoke(generated_code.content)\n","print(\"code_solution\", code_solution)"],"metadata":{"id":"gOuEOxKuAdH0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(code_solution.imports)"],"metadata":{"id":"M6jXl7MhBRMp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(code_solution.code)"],"metadata":{"id":"Gkj71piQBWwu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pydantic import BaseModel, Field\n","\n","class code(BaseModel):\n","    \"\"\"Schema for code solutions.\"\"\"\n","\n","    prefix: str = Field(description=\"Description of the problem and approach\")\n","    imports: str = Field(description=\"Code block import statements\")\n","    code: str = Field(description=\"Code block not including import statements\")"],"metadata":{"id":"9vT6fLpC97mB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_core.prompts import ChatPromptTemplate\n","\n","GENERATE_CODE_TEMPLATE = \"\"\"\n","Given the following pandas `describe()` output of a dataset,\n","\n","write a **directly executable Python code** to:\n","1. handle missing values,         (# 결측치 처리)\n","2. convert categorical columns,\n","3. ...any additional preprocessing needed,  (추가 전처리가 필요하면 해줘라)\n","4. prepare the dataset for machine learning.  (머신러닝에 쓸 수 있도록 데이터 준비해달라)\n","\n","Here is the describe result of the dataset:\n","\\n ------- \\n  {context} \\n ------- \\n\n","\n","Do not wrap the code in a function and the response in any backticks or anything else. The code should be written as a flat script, so that it can be run immediately and any errors will be visible during execution.\n","Ensure any code you provide can be executed \\n\n","with all required imports and variables defined. Structure your answer with a description of the code solution. \\n\n","Then list the imports. And finally list the functioning code block.\n","\"\"\"\n","\n","code_gen_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"user\", GENERATE_CODE_TEMPLATE),\n","    ]\n",")"],"metadata":{"id":"T_7DytvJ-WI0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_anthropic import ChatAnthropic\n","\n","llm_claude= ChatAnthropic(model=\"claude-sonnet-4-20250514\")"],"metadata":{"id":"jUPJJw8b_O6B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install langgraph"],"metadata":{"id":"vq6kzjQF_gRk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langgraph.graph import StateGraph, MessagesState\n","\n","class State(MessagesState): # messages\n","\n","    \"\"\"\n","    Represents the state of our graph.\n","    Attributes:\n","        error : Binary flag for control flow to indicate whether test error was tripped\n","        context: Data summary\n","        generation : Code solution\n","        iterations : Number of tries\n","    \"\"\"\n","\n","    error: str # yes or no\n","    context: str\n","    generation: str\n","    iterations: int\n","graph_builder = StateGraph(State)"],"metadata":{"id":"nvPwuCYoE8V0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_core.tools import tool\n","import pandas as pd\n","\n","@tool\n","def describe_data(csv: str) -> str:\n","    \"\"\"Describe the date column in the dataframe.\n","    Args:\n","        csv: csv data path string\n","    \"\"\"\n","    df = pd.read_csv(csv)\n","    describe_str = f\"\"\"Data: {csv}\"\"\" + df.describe(include='all').to_string()\n","    return describe_str"],"metadata":{"id":"Z6yAgi50FSeQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["llm_with_tools = llm_gpt.bind_tools(tools=[describe_data])"],"metadata":{"id":"vIhhPOGiFVwk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def chatbot(state: State):\n","    print(\"##### HI ! #####\")\n","    response = llm_with_tools.invoke(state[\"messages\"])\n","    print(\"첫번째 LLM 호출 결과 : \", response)\n","    return {\"messages\": [response]}\n","\n","graph_builder.add_node(\"chatbot\", chatbot)"],"metadata":{"id":"QEC-OAa2Fsi-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def add_context(state: State):\n","    print(\"##### ADD CONTEXT #####\")\n","    if messages := state.get(\"messages\", []):\n","        message = messages[-1] # 마지막 message\n","    else:\n","        raise ValueError(\"No message found in input\")\n","\n","    for tool_call in message.tool_calls:\n","        for tool in tools:\n","            if tool.name == tool_call['name']:\n","                describe_str = tool.invoke(tool_call['args'])\n","\n","    # Get context from describe_data tool\n","    print(\"데이터 통계 (context) : \", describe_str[:100])\n","    return {\"context\": describe_str}\n","\n","graph_builder.add_node(\"add_context\", add_context)"],"metadata":{"id":"vkYbE-uzF6Qh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langgraph.graph import END\n","\n","def guardrail_route(\n","    state: State,\n","):\n","    \"\"\"\n","    Use in the conditional_edge to route to the ToolNode if the last message\n","    has tool calls. Otherwise, route to the end.\n","    \"\"\"\n","    if isinstance(state, list):\n","        ai_message = state[-1]\n","    elif messages := state.get(\"messages\", []):\n","        ai_message = messages[-1]\n","    else:\n","        raise ValueError(f\"No messages found in input state to tool_edge: {state}\")\n","    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n","        return \"add_context\"\n","    return END\n","graph_builder.add_conditional_edges(\n","    \"chatbot\",\n","    guardrail_route,\n","    {\"add_context\": \"add_context\", END: END},\n",")"],"metadata":{"id":"i7uUTqo5GhhW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pydantic import BaseModel, Field\n","class code(BaseModel):\n","    \"\"\"Schema for code solutions.\"\"\"\n","    prefix: str = Field(description=\"Description of the problem and approach\")\n","    imports: str = Field(description=\"Code block import statements\")\n","    code: str = Field(description=\"Code block not including import statements\")"],"metadata":{"id":"vUXnWHjqHW96"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_core.prompts import ChatPromptTemplate\n","GENERATE_CODE_TEMPLATE = \"\"\"\n","Given the following pandas `describe()` output of a dataset,\n","write a **directly executable Python code** to:\n","1. handle missing values,\n","2. convert categorical columns,\n","3. ...any additional preprocessing needed,\n","4. prepare the dataset for machine learning.\n","Here is the describe result of the dataset:\n","\\n ------- \\n  {context} \\n ------- \\n\n","Do not wrap the code in a function and the response in any backticks or anything else. The code should be written as a flat script, so that it can be run immediately and any errors will be visible during execution.\n","Ensure any code you provide can be executed \\n\n","with all required imports and variables defined. Structure your answer with a description of the code solution. \\n\n","Then list the imports. And finally list the functioning code block.\n","\"\"\"\n","code_gen_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\"user\", GENERATE_CODE_TEMPLATE),\n","    ]\n",")"],"metadata":{"id":"8lXrIJmXHXR0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def generate(state: State):\n","    print(\"##### GENERATING CODE SOLUTION #####\")\n","    context = state[\"context\"]\n","    generated_code = llm_claude.invoke(\n","        code_gen_prompt.format_messages(context=context)\n","    )\n","    code_structurer = llm_gpt.with_structured_output(code)\n","    code_solution = code_structurer.invoke(generated_code.content)\n","    messages = [\n","        (\n","            \"assistant\",\n","            f\"{code_solution.prefix} \\n Imports: {code_solution.imports} \\n Code: {code_solution.code}\",\n","        )\n","    ]\n","    return {\"generation\": code_solution, \"messages\": messages}\n","graph_builder.add_node(\"generate\", generate)"],"metadata":{"id":"wwKHdcTLHav2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def code_check(state: State):\n","    print(\"##### CHECKING CODE #####\")\n","    code_solution = state[\"generation\"]\n","    imports = code_solution.imports\n","    code = code_solution.code\n","    # Check imports\n","    try:\n","        exec(imports)\n","    except Exception as e:\n","        print(\"---CODE IMPORT CHECK: FAILED---\")\n","        error_message = [(\"user\", f\"Your solution failed the import test: {e}\")]\n","        print(\"에러 메시지 : \", error_message)\n","        return {\n","            \"generation\": code_solution,\n","            \"messages\": error_message,\n","            \"error\": \"yes\",\n","        }\n","    # Check execution\n","    try:\n","        exec(imports + \"\\n\" + code)\n","    except Exception as e:\n","        print(\"---CODE BLOCK CHECK: FAILED---\")\n","        error_message = [(\"user\", f\"Your solution failed the code execution test: {e}\")]\n","        print(\"에러 메시지 : \", error_message)\n","        return {\n","            \"generation\": code_solution,\n","            \"messages\": error_message,\n","            \"error\": \"yes\",\n","        }\n","    # No errors\n","    print(\"---NO CODE TEST FAILURES---\")\n","    return {\n","        \"generation\": code_solution,\n","        \"error\": \"no\",\n","    }\n","graph_builder.add_node(\"code_check\", code_check)"],"metadata":{"id":"4Tyz4ra0H5oV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langchain_core.prompts import ChatPromptTemplate\n","reflect_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"\"\"\n","            You are given an error message that occurred while running a Python script, along with the original code that produced the error.\n","            Provide a corrected version of the original code that resolves the issue.\n","            Ensure the code runs without errors and maintains the intended functionality.\"\"\"\n","        ),\n","        (\n","            \"user\",\n","            \"\"\"\n","            --- ERROR MESSAGE ---\n","            {error}\n","            --- ORIGINAL CODE ---\n","            {code_solution}\n","            ----------------------\n","            Ensure any code you provide can be executed \\n\n","            with all required imports and variables defined. Structure your answer with a description of the code solution. \\n\n","            Then list the imports. And finally list the functioning code block.\"\"\",\n","        )\n","    ]\n",")"],"metadata":{"id":"c1dtMu5CI6P1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def reflect(state: State):\n","    print(\"---REFLECTING CODE SOLUTION---\")\n","    error = state[\"messages\"][-1].content\n","    code_solution = state[\"generation\"]\n","    code_solution = f\"{code_solution.prefix} \\n Imports: {code_solution.imports} \\n Code: {code_solution.code}\"\n","    corrected_code = llm_claude.invoke(reflect_prompt.format_messages(error=error, code_solution=code_solution))\n","    code_structurer = llm_gpt.with_structured_output(code)\n","    reflections = code_structurer.invoke(corrected_code.content)\n","    print(\"수정된 코드 : \", reflections)\n","    messages = [\n","        (\n","            \"assistant\",\n","            f\"{reflections.prefix} \\n Imports: {reflections.imports} \\n Code: {reflections.code}\",\n","        )\n","    ]\n","    return {\"generation\": reflections, \"messages\": messages, \"iterations\": state[\"iterations\"] + 1}\n","graph_builder.add_node(\"reflect\", reflect)"],"metadata":{"id":"nNaSse5cJrc6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def decide_to_finish(state: State):\n","    error = state[\"error\"]\n","    iterations = state[\"iterations\"]\n","    if error == \"no\" or iterations == max_iterations: # 에러가 없거나 max_iterations에 도달하면 종료\n","        print(\"---DECISION: FINISH---\")\n","        return \"end\"\n","    else:\n","        print(\"---DECISION: RE-TRY SOLUTION---\")\n","        return \"reflect\""],"metadata":{"id":"gEw34--dJt-e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from langgraph.graph import START, END\n","graph_builder.add_edge(START, \"chatbot\")\n","graph_builder.add_edge(\"add_context\", \"generate\")\n","graph_builder.add_edge(\"generate\", \"code_check\")\n","graph_builder.add_conditional_edges(\n","    \"code_check\",\n","    decide_to_finish,\n","    {\n","        \"end\": END,\n","        \"reflect\": \"reflect\"\n","    },\n",")\n","graph_builder.add_edge(\"reflect\", \"code_check\")\n","graph = graph_builder.compile()\n","graph"],"metadata":{"id":"qLBlF3oKJvdU"},"execution_count":null,"outputs":[]}]}